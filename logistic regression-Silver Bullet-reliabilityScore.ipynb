{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('model_data_new.csv').drop(columns = ['Unnamed: 0','f_highrate','f_lowrate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'prev_CW/SA_rate', 'status',\n",
       "       'S_create2SA_Create', 'S_Create2Start_Time', 'SA_Create2Start_Time',\n",
       "       'U_create2now', 'U_approve2now', 'prev_CW x SA_rate', 'type_RN',\n",
       "       'type_LVN+LPN', 'type_STNA', 'segmentName_d', 'areaName_houston',\n",
       "       'areaName_no', 'areaName_dfw', 'areaName_austin', 'areaName_san',\n",
       "       'net_pay', 'target', 'sa_create', 'Start_Time', 'CW_in_a_month',\n",
       "       'count_prev_SA', 'count_prev_CW', 'type_CNA', 'reliability_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice df by the end of this week, for predcition output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import date, timedelta\n",
    "tmrrw = date.today() + timedelta(days=1)\n",
    "\n",
    "end_of_week = str(tmrrw.year) + '-' + str(tmrrw.month) + '-' + str(tmrrw.day+1)\n",
    "\n",
    "# convert to datetime for conditonal selection\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "# sort by start time -> for slicing\n",
    "df = df.sort_values(by = 'Start_Time') \n",
    "# record as realdata\n",
    "realdata = df[df['Start_Time'].apply(lambda x: x > pd.to_datetime(end_of_week))]\n",
    "# record predction output rows, don't include it in tran test validation\n",
    "realdata_len = realdata.shape[0]\n",
    "# only keep status = confirmed\n",
    "realdata = realdata[realdata['status'] == 'confirmed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set: 1000 recently records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    934\n",
       "1     66\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice, dont include realdata\n",
    "validation = df[-1000-realdata_len : -realdata_len]\n",
    "\n",
    "y_valid = validation['target']\n",
    "x_valid = validation.drop(['id','user_id', 'shift_id', 'status', 'sa_create', 'Start_Time', 'target'], axis = 1)\n",
    "\n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test: main dataset - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-1000-realdata_len] # slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)\n",
    "y = df['target']\n",
    "\n",
    "# set test, train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make experienment dataset\n",
    "df1 = df[(df['areaName_no'] == 1) & (df['type_STNA']==1)]\n",
    "X_exp = df1.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)\n",
    "y_exp = df1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69261\n",
       "1     5742\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=100000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "# assign less punlishment for classifying 0 as 1 -> find more 1's\n",
    "# weights = {0:1, 1:10}\n",
    "# class_weight = 'balanced': automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "logit = LogisticRegression(solver = 'lbfgs', max_iter=100000, class_weight = 'balanced')\n",
    "logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15020  5705]\n",
      " [  439  1337]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83     20725\n",
      "           1       0.19      0.75      0.30      1776\n",
      "\n",
      "    accuracy                           0.73     22501\n",
      "   macro avg       0.58      0.74      0.57     22501\n",
      "weighted avg       0.91      0.73      0.79     22501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = logit.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.582050\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "\n",
    "# predict probabilities\n",
    "yhat = logit.predict_proba(X_exp)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_exp,yhat)\n",
    "\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "\n",
    "lower_limiter = thresholds[ix]\n",
    "print('Best Threshold=%f' % (lower_limiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold=0.706\n"
     ]
    }
   ],
   "source": [
    "# search thresholds for imbalanced classification\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "# predict probabilities\n",
    "yhat = logit.predict_proba(X_exp)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:, 1]\n",
    "# define thresholds\n",
    "thresholds = arange(0, 1, 0.001)\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_exp, to_labels(probs, t)) for t in thresholds]\n",
    "# get best threshold\n",
    "ix = argmax(scores)\n",
    "\n",
    "higher_limiter = thresholds[ix]\n",
    "\n",
    "print('Best threshold=%.3f' % (higher_limiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cf_matrix import make_confusion_matrix\n",
    "# labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "# categories = ['Zero', 'One']\n",
    "# make_confusion_matrix(confusion_matrix(y_test, y_pred), \n",
    "#                       group_names=labels,\n",
    "#                       categories=categories, \n",
    "#                       cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222447\n",
      "         Iterations 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td> 52502</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 52480</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    21</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 31 May 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.1692</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:36:19</td>     <th>  Log-Likelihood:    </th> <td> -11679.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -14057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prev_CW/SA_rate</th>      <td>    0.5790</td> <td>    0.256</td> <td>    2.260</td> <td> 0.024</td> <td>    0.077</td> <td>    1.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_create2SA_Create</th>   <td>    0.0004</td> <td> 1264.195</td> <td> 3.29e-07</td> <td> 1.000</td> <td>-2477.777</td> <td> 2477.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_Create2Start_Time</th>  <td>   -0.0005</td> <td> 1264.195</td> <td> -3.6e-07</td> <td> 1.000</td> <td>-2477.778</td> <td> 2477.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SA_Create2Start_Time</th> <td>   -0.0019</td> <td> 1264.195</td> <td>-1.49e-06</td> <td> 1.000</td> <td>-2477.779</td> <td> 2477.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>U_create2now</th>         <td>   -0.0034</td> <td>    0.007</td> <td>   -0.487</td> <td> 0.626</td> <td>   -0.017</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>U_approve2now</th>        <td>   -0.0071</td> <td>    0.008</td> <td>   -0.908</td> <td> 0.364</td> <td>   -0.022</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prev_CW x SA_rate</th>    <td>    0.0001</td> <td> 2.59e-05</td> <td>    4.707</td> <td> 0.000</td> <td>  7.1e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_RN</th>              <td>   -3.5626</td> <td>    0.176</td> <td>  -20.262</td> <td> 0.000</td> <td>   -3.907</td> <td>   -3.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_LVN+LPN</th>         <td>   -1.3619</td> <td>    0.111</td> <td>  -12.244</td> <td> 0.000</td> <td>   -1.580</td> <td>   -1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_STNA</th>            <td>   -0.1393</td> <td>    0.113</td> <td>   -1.234</td> <td> 0.217</td> <td>   -0.361</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>segmentName_d</th>        <td>    0.3087</td> <td>    0.086</td> <td>    3.604</td> <td> 0.000</td> <td>    0.141</td> <td>    0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_houston</th>     <td>   -2.6594</td> <td>    0.141</td> <td>  -18.927</td> <td> 0.000</td> <td>   -2.935</td> <td>   -2.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_no</th>          <td>   -2.1983</td> <td>    0.150</td> <td>  -14.647</td> <td> 0.000</td> <td>   -2.492</td> <td>   -1.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_dfw</th>         <td>   -2.7175</td> <td>    0.151</td> <td>  -17.991</td> <td> 0.000</td> <td>   -3.014</td> <td>   -2.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_austin</th>      <td>   -2.6311</td> <td>    0.164</td> <td>  -16.071</td> <td> 0.000</td> <td>   -2.952</td> <td>   -2.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_san</th>         <td>   -2.6386</td> <td>    0.163</td> <td>  -16.225</td> <td> 0.000</td> <td>   -2.957</td> <td>   -2.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_pay</th>              <td>    0.1144</td> <td>    0.004</td> <td>   28.578</td> <td> 0.000</td> <td>    0.107</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CW_in_a_month</th>        <td>   -0.3372</td> <td>    0.043</td> <td>   -7.837</td> <td> 0.000</td> <td>   -0.422</td> <td>   -0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_prev_SA</th>        <td>    0.0017</td> <td>    0.000</td> <td>    6.910</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_prev_CW</th>        <td>   -0.1591</td> <td>    0.010</td> <td>  -16.433</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_CNA</th>             <td>    0.3247</td> <td>    0.090</td> <td>    3.610</td> <td> 0.000</td> <td>    0.148</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reliability_score</th>    <td>   -0.0377</td> <td>    0.001</td> <td>  -46.436</td> <td> 0.000</td> <td>   -0.039</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                52502\n",
       "Model:                          Logit   Df Residuals:                    52480\n",
       "Method:                           MLE   Df Model:                           21\n",
       "Date:                Mon, 31 May 2021   Pseudo R-squ.:                  0.1692\n",
       "Time:                        10:36:19   Log-Likelihood:                -11679.\n",
       "converged:                       True   LL-Null:                       -14057.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "prev_CW/SA_rate          0.5790      0.256      2.260      0.024       0.077       1.081\n",
       "S_create2SA_Create       0.0004   1264.195   3.29e-07      1.000   -2477.777    2477.778\n",
       "S_Create2Start_Time     -0.0005   1264.195   -3.6e-07      1.000   -2477.778    2477.777\n",
       "SA_Create2Start_Time    -0.0019   1264.195  -1.49e-06      1.000   -2477.779    2477.775\n",
       "U_create2now            -0.0034      0.007     -0.487      0.626      -0.017       0.010\n",
       "U_approve2now           -0.0071      0.008     -0.908      0.364      -0.022       0.008\n",
       "prev_CW x SA_rate        0.0001   2.59e-05      4.707      0.000     7.1e-05       0.000\n",
       "type_RN                 -3.5626      0.176    -20.262      0.000      -3.907      -3.218\n",
       "type_LVN+LPN            -1.3619      0.111    -12.244      0.000      -1.580      -1.144\n",
       "type_STNA               -0.1393      0.113     -1.234      0.217      -0.361       0.082\n",
       "segmentName_d            0.3087      0.086      3.604      0.000       0.141       0.477\n",
       "areaName_houston        -2.6594      0.141    -18.927      0.000      -2.935      -2.384\n",
       "areaName_no             -2.1983      0.150    -14.647      0.000      -2.492      -1.904\n",
       "areaName_dfw            -2.7175      0.151    -17.991      0.000      -3.014      -2.421\n",
       "areaName_austin         -2.6311      0.164    -16.071      0.000      -2.952      -2.310\n",
       "areaName_san            -2.6386      0.163    -16.225      0.000      -2.957      -2.320\n",
       "net_pay                  0.1144      0.004     28.578      0.000       0.107       0.122\n",
       "CW_in_a_month           -0.3372      0.043     -7.837      0.000      -0.422      -0.253\n",
       "count_prev_SA            0.0017      0.000      6.910      0.000       0.001       0.002\n",
       "count_prev_CW           -0.1591      0.010    -16.433      0.000      -0.178      -0.140\n",
       "type_CNA                 0.3247      0.090      3.610      0.000       0.148       0.501\n",
       "reliability_score       -0.0377      0.001    -46.436      0.000      -0.039      -0.036\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logit summary\n",
    "import statsmodels.api as sm\n",
    "smlogit = sm.Logit(y_train,X_train).fit()\n",
    "smlogit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting? No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35327 13209]\n",
      " [  946  3020]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83     48536\n",
      "           1       0.19      0.76      0.30      3966\n",
      "\n",
      "    accuracy                           0.73     52502\n",
      "   macro avg       0.58      0.74      0.57     52502\n",
      "weighted avg       0.91      0.73      0.79     52502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43626  4910]\n",
      " [ 2074  1892]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93     48536\n",
      "           1       0.28      0.48      0.35      3966\n",
      "\n",
      "    accuracy                           0.87     52502\n",
      "   macro avg       0.62      0.69      0.64     52502\n",
      "weighted avg       0.90      0.87      0.88     52502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test threshold\n",
    "limiter = higher_limiter\n",
    "\n",
    "y_prob = list(logit.predict_proba(X_train)[:,1])\n",
    "y_pred = []\n",
    "count =0\n",
    "for prob in y_prob:\n",
    "    if prob >= limiter:\n",
    "        y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[647 287]\n",
      " [ 17  49]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.69      0.81       934\n",
      "           1       0.15      0.74      0.24        66\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.56      0.72      0.53      1000\n",
      "weighted avg       0.92      0.70      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test threshold\n",
    "limiter = higher_limiter\n",
    "\n",
    "y_prob = list(logit.predict_proba(x_valid)[:,1])\n",
    "y_pred = []\n",
    "count =0\n",
    "for prob in y_prob:\n",
    "    if prob >= limiter:\n",
    "        y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The limiter we adopt is 0.706\n",
      "By covering 0.336 labeled as high probability of UCW, we have prepared for 0.742 of real UCW\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "label_coverage = y_pred.count(1)/len(y_pred)\n",
    "UCW_coverage = recall_score(y_valid, y_pred)\n",
    "\n",
    "print('The limiter we adopt is %.3f' % (limiter))\n",
    "print('By covering %.3f labeled as high probability of UCW, we have prepared for %.3f of real UCW' \n",
    "      % (label_coverage,UCW_coverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit real data in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input\n",
    "real_X = realdata.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concat predicted prob with data\n",
    "realdata['prob'] = list(logit.predict_proba(real_X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74570</th>\n",
       "      <td>194405</td>\n",
       "      <td>2021-06-02 05:00:00</td>\n",
       "      <td>0.478321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76905</th>\n",
       "      <td>190008</td>\n",
       "      <td>2021-06-02 05:00:00</td>\n",
       "      <td>0.601106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74944</th>\n",
       "      <td>194471</td>\n",
       "      <td>2021-06-02 05:00:00</td>\n",
       "      <td>0.554104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76950</th>\n",
       "      <td>194394</td>\n",
       "      <td>2021-06-02 05:00:00</td>\n",
       "      <td>0.842791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67242</th>\n",
       "      <td>195550</td>\n",
       "      <td>2021-06-02 05:45:00</td>\n",
       "      <td>0.609690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          Start_Time      prob\n",
       "74570  194405 2021-06-02 05:00:00  0.478321\n",
       "76905  190008 2021-06-02 05:00:00  0.601106\n",
       "74944  194471 2021-06-02 05:00:00  0.554104\n",
       "76950  194394 2021-06-02 05:00:00  0.842791\n",
       "67242  195550 2021-06-02 05:45:00  0.609690"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record when this prediction is ran\n",
    "from datetime import date\n",
    "time = str(date.today().year) + '-' + str(date.today().month) + '-' + str(date.today().day)\n",
    "limiter = round(limiter,2)\n",
    "realdata[['id', 'Start_Time', 'prob']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74570   2021-06-02 05:00:00\n",
       "76905   2021-06-02 05:00:00\n",
       "74944   2021-06-02 05:00:00\n",
       "76950   2021-06-02 05:00:00\n",
       "67242   2021-06-02 05:45:00\n",
       "                ...        \n",
       "31186   2021-07-10 07:00:00\n",
       "41149   2021-07-10 17:00:00\n",
       "19719   2021-07-11 17:00:00\n",
       "41150   2021-07-11 17:00:00\n",
       "31187   2021-07-12 07:00:00\n",
       "Name: Start_Time, Length: 832, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make the prediction doesn't include today\n",
    "realdata['Start_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob = realdata[['id', 'Start_Time', 'prob']][realdata['prob'] > limiter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append newly processed data to prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# specify connection to database\n",
    "import psycopg2\n",
    "connection = psycopg2.connect(\n",
    "    host=\"nursedash-prod.cuzi2kducsnv.us-east-1.rds.amazonaws.com\",\n",
    "    database=\"nursedash\",\n",
    "    user=\"external_analyst\",\n",
    "    password=\"uDps8APganhSLc3K2xe7NtMPq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> all time to chicago time, No withdrawn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT  sa.id, sa.user_id, sa.shift_id, f.id AS facility_id, sa.\"withdrawnInfo\" -> 'initiator' as withdrawnInfo_value,\n",
    "sa.\"status\", sa.\"prevStatus\", sa.\"distance\", s.\"facility_id\", \"s\".\"description\" AS \"shift_description\",\n",
    "\"s\".\"assigned_nurse_id\", s.\"net_pay\", \"s\".\"unit\" AS \"s_unit\",s.\"type\",\n",
    "\"s\".\"qualifications\" AS \"s_qualifications\", \"s\".\"breakTime\" AS \"s_breakTime\", sa.\"withdrawnInfo\",\n",
    "\"f\".\"name\" AS \"facility_name\",\"f\".\"short_name\" AS \"f_short_name\", f.\"segmentName\", f.\"areaName\",\n",
    "timezone('America/Chicago', s.\"createdAt\") as s_create,\n",
    "timezone('America/Chicago', sa.\"createdAt\") as sa_create,\n",
    "timezone('America/Chicago', u.\"approvedAt\") as u_approve,\n",
    "timezone('America/Chicago', u.\"createdAt\") as u_create,\n",
    "timezone('America/Chicago', sa.\"statusUpdatedAt\") as sa_statusUpdate,\n",
    "timezone('America/Chicago', timezone('UTC', s.start_time)) AS \"Start_Time\" \n",
    "FROM shifts s\n",
    "INNER JOIN shift_applications sa ON s.id = sa.shift_id\n",
    "INNER JOIN facilities f ON s.facility_id = f.id\n",
    "INNER JOIN users u ON sa.user_id = u.id\n",
    "\n",
    "\"\"\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'facility_id', 'withdrawninfo_value',\n",
       "       'status', 'prevStatus', 'distance', 'facility_id', 'shift_description',\n",
       "       'assigned_nurse_id', 'net_pay', 's_unit', 'type', 's_qualifications',\n",
       "       's_breakTime', 'withdrawnInfo', 'facility_name', 'f_short_name',\n",
       "       'segmentName', 'areaName', 's_create', 'sa_create', 'u_approve',\n",
       "       'u_create', 'sa_statusupdate', 'Start_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_day(hour):\n",
    "    return (\n",
    "        \"morning\" if 4 < hour <= 12\n",
    "        else\n",
    "        \"afternoon\" if 12 < hour <= 17\n",
    "        else\n",
    "        \"evening/night\" if 18 < hour <= 22\n",
    "        else\n",
    "        \"overnight\"\n",
    "\n",
    "    )\n",
    "\n",
    "df['Start_time_of_the_day'] = df.apply(lambda row: get_part_of_day(row['Start_Time'].hour), axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine the prediction file with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the prediction file\n",
    "prediction = realdata[['id', 'Start_Time', 'prob']]\n",
    "validation = prediction.merge(df, on = 'id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# convert to datetime for conditonal selection\n",
    "validation['Start_Time_x'] = pd.to_datetime(validation['Start_Time_x'])\n",
    "\n",
    "# only select date part of the time\n",
    "validation['Start_Time_x'] = validation.apply(lambda row: str(row['Start_Time_x'].date()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename start time\n",
    "validation = validation.rename(columns={\"Start_Time_x\": \"Start_Time\"})\n",
    "\n",
    "# limit our result to what we want as validation file\n",
    "validation = validation[['id','prob','Start_Time','Start_time_of_the_day','status','type','prevStatus','areaName','segmentName','facility_name','user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prob', 'Start_Time', 'Start_time_of_the_day', 'status', 'type',\n",
       "       'prevStatus', 'areaName', 'segmentName', 'facility_name', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = validation.set_index(\"id\")\n",
    "validation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.to_csv('pred_{}_Silver_Bullet.csv'.format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>Start_time_of_the_day</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "      <th>prevStatus</th>\n",
       "      <th>areaName</th>\n",
       "      <th>segmentName</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194405</th>\n",
       "      <td>0.478321</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Broadview Heights</td>\n",
       "      <td>17061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190008</th>\n",
       "      <td>0.601106</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>18857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194471</th>\n",
       "      <td>0.554104</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Broadview Heights</td>\n",
       "      <td>17296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194394</th>\n",
       "      <td>0.842791</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Broadview Heights</td>\n",
       "      <td>18996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195550</th>\n",
       "      <td>0.609690</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>CNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Heartis Clear Lake</td>\n",
       "      <td>14488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191649</th>\n",
       "      <td>0.006786</td>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>RN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Woodlands Specialty Hospital</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192531</th>\n",
       "      <td>0.028987</td>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192145</th>\n",
       "      <td>0.135550</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>4733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192532</th>\n",
       "      <td>0.027985</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191650</th>\n",
       "      <td>0.006281</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>RN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Woodlands Specialty Hospital</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prob  Start_Time Start_time_of_the_day     status  type  \\\n",
       "id                                                                    \n",
       "194405  0.478321  2021-06-02               morning  confirmed  STNA   \n",
       "190008  0.601106  2021-06-02               morning  confirmed  STNA   \n",
       "194471  0.554104  2021-06-02               morning  confirmed  STNA   \n",
       "194394  0.842791  2021-06-02               morning  confirmed  STNA   \n",
       "195550  0.609690  2021-06-02               morning  confirmed   CNA   \n",
       "...          ...         ...                   ...        ...   ...   \n",
       "191649  0.006786  2021-07-10               morning  confirmed    RN   \n",
       "192531  0.028987  2021-07-10             afternoon  confirmed  STNA   \n",
       "192145  0.135550  2021-07-11             afternoon  confirmed  STNA   \n",
       "192532  0.027985  2021-07-11             afternoon  confirmed  STNA   \n",
       "191650  0.006281  2021-07-12               morning  confirmed    RN   \n",
       "\n",
       "       prevStatus        areaName    segmentName  \\\n",
       "id                                                 \n",
       "194405   selected  Northeast Ohio  Senior Living   \n",
       "190008   selected  Northeast Ohio  Senior Living   \n",
       "194471   selected  Northeast Ohio  Senior Living   \n",
       "194394   selected  Northeast Ohio  Senior Living   \n",
       "195550   selected         Houston  Senior Living   \n",
       "...           ...             ...            ...   \n",
       "191649   selected         Houston     Healthcare   \n",
       "192531   selected  Northeast Ohio  Senior Living   \n",
       "192145   selected  Northeast Ohio  Senior Living   \n",
       "192532   selected  Northeast Ohio  Senior Living   \n",
       "191650   selected         Houston     Healthcare   \n",
       "\n",
       "                       facility_name  user_id  \n",
       "id                                             \n",
       "194405   Avenue at Broadview Heights    17061  \n",
       "190008         CareCore at Willowood    18857  \n",
       "194471   Avenue at Broadview Heights    17296  \n",
       "194394   Avenue at Broadview Heights    18996  \n",
       "195550            Heartis Clear Lake    14488  \n",
       "...                              ...      ...  \n",
       "191649  Woodlands Specialty Hospital     7894  \n",
       "192531         CareCore at Willowood     9428  \n",
       "192145         CareCore at Willowood     4733  \n",
       "192532         CareCore at Willowood     9428  \n",
       "191650  Woodlands Specialty Hospital     7894  \n",
       "\n",
       "[832 rows x 10 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation#.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only northeast ohio and stna, and make a pivot table\n",
    "# create a column called count\n",
    "pivot_table = validation[(validation['areaName'] == 'Northeast Ohio') & \n",
    "           (validation['type'] == 'STNA') & (validation['prob'] > 0.55)].groupby([\"Start_Time\",\n",
    "                                    \"Start_time_of_the_day\"]).size().reset_index(name='count').set_index(\"Start_Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the count is above limiter of 5\n",
    "# pivot_table['above_limiter'] = pivot_table.apply(lambda row: 2 if row['count'] >= 5 else 0, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_time_of_the_day</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>morning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>overnight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>morning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>overnight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>morning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>morning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>overnight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-06</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-06</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-06</th>\n",
       "      <td>overnight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-07</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-07</th>\n",
       "      <td>morning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-08</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-09</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Start_time_of_the_day  count\n",
       "Start_Time                             \n",
       "2021-06-02             afternoon      3\n",
       "2021-06-02               morning      4\n",
       "2021-06-02             overnight      2\n",
       "2021-06-03             afternoon      3\n",
       "2021-06-03               morning      2\n",
       "2021-06-03             overnight      1\n",
       "2021-06-04               morning      2\n",
       "2021-06-05               morning      3\n",
       "2021-06-05             overnight      1\n",
       "2021-06-06             afternoon      1\n",
       "2021-06-06               morning      1\n",
       "2021-06-06             overnight      2\n",
       "2021-06-07             afternoon      1\n",
       "2021-06-07               morning      2\n",
       "2021-06-08               morning      1\n",
       "2021-06-09               morning      1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.to_excel(\"plan2_pred_{}.xlsx\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
