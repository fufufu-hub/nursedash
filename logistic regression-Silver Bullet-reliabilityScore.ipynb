{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('model_data.csv').drop(columns = ['Unnamed: 0','f_highrate','f_lowrate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'prev_CW/SA_rate', 'status',\n",
       "       'U_approve2now', 'prev_CW x SA_rate', 'type_RN', 'type_LVN+LPN',\n",
       "       'type_STNA', 'segmentName_d', 'net_pay', 'target', 'sa_create',\n",
       "       'Start_Time', 'areaName_Austin', 'areaName_Cincinnati', 'areaName_DFW',\n",
       "       'areaName_Houston', 'areaName_Northeast Ohio', 'count_prev_SA',\n",
       "       'count_prev_CW', 'type_CNA', 'reliability_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice df by the end of this week, for predcition output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "tmrrw = date.today() + timedelta(days=1)\n",
    "\n",
    "end_of_week = str(tmrrw.year) + '-' + str(tmrrw.month) + '-' + str(tmrrw.day+1)\n",
    "\n",
    "# convert to datetime for conditonal selection\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "# sort by start time -> for slicing\n",
    "df = df.sort_values(by = 'Start_Time') \n",
    "# record as realdata\n",
    "realdata = df[df['Start_Time'].apply(lambda x: x > pd.to_datetime(end_of_week))]\n",
    "# record predction output rows, don't include it in tran test validation\n",
    "realdata_len = realdata.shape[0]\n",
    "# only keep status = confirmed\n",
    "realdata = realdata[realdata['status'] == 'confirmed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set: 1000 recently records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    918\n",
       "1     82\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice, dont include realdata\n",
    "validation = df[-1000-realdata_len : -realdata_len]\n",
    "\n",
    "y_valid = validation['target']\n",
    "x_valid = validation.drop(['id','user_id', 'shift_id', 'status', 'sa_create', 'Start_Time', 'target'], axis = 1)\n",
    "\n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test: main dataset - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-1000-realdata_len] # slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)\n",
    "y = df['target']\n",
    "\n",
    "# set test, train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make experienment dataset\n",
    "df1 = df[(df['areaName_Northeast Ohio'] == 1) & (df['type_STNA']==1)]\n",
    "X_exp = df1.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)\n",
    "y_exp = df1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72452\n",
       "1     5973\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=100000)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "# assign less punlishment for classifying 0 as 1 -> find more 1's\n",
    "# weights = {0:1, 1:10}\n",
    "# class_weight = 'balanced': automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "logit = LogisticRegression(solver = 'lbfgs', max_iter=100000, class_weight = 'balanced')\n",
    "logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14798  6957]\n",
      " [  615  1158]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.68      0.80     21755\n",
      "           1       0.14      0.65      0.23      1773\n",
      "\n",
      "    accuracy                           0.68     23528\n",
      "   macro avg       0.55      0.67      0.52     23528\n",
      "weighted avg       0.90      0.68      0.75     23528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = logit.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.549319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "\n",
    "# predict probabilities\n",
    "yhat = logit.predict_proba(X_exp)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_exp,yhat)\n",
    "\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "\n",
    "lower_limiter = thresholds[ix]\n",
    "print('Best Threshold=%f' % (lower_limiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold=0.657\n"
     ]
    }
   ],
   "source": [
    "# search thresholds for imbalanced classification\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "# predict probabilities\n",
    "yhat = logit.predict_proba(X_exp)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:, 1]\n",
    "# define thresholds\n",
    "thresholds = arange(0, 1, 0.001)\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_exp, to_labels(probs, t)) for t in thresholds]\n",
    "# get best threshold\n",
    "ix = argmax(scores)\n",
    "\n",
    "higher_limiter = thresholds[ix]\n",
    "\n",
    "print('Best threshold=%.3f' % (higher_limiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cf_matrix import make_confusion_matrix\n",
    "# labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "# categories = ['Zero', 'One']\n",
    "# make_confusion_matrix(confusion_matrix(y_test, y_pred), \n",
    "#                       group_names=labels,\n",
    "#                       categories=categories, \n",
    "#                       cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.260807\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>   <td> 54897</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td> 54880</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    16</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 07 Jun 2021</td> <th>  Pseudo R-squ.:     </th>   <td>0.03460</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:46:03</td>     <th>  Log-Likelihood:    </th>  <td> -14318.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -14831.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.720e-208</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prev_CW/SA_rate</th>         <td>    2.3308</td> <td>    0.201</td> <td>   11.584</td> <td> 0.000</td> <td>    1.936</td> <td>    2.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>U_approve2now</th>           <td>   -0.0469</td> <td>    0.003</td> <td>  -17.046</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prev_CW x SA_rate</th>       <td>    0.0001</td> <td> 2.32e-05</td> <td>    4.565</td> <td> 0.000</td> <td> 6.05e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_RN</th>                 <td>   -2.5319</td> <td>    0.143</td> <td>  -17.734</td> <td> 0.000</td> <td>   -2.812</td> <td>   -2.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_LVN+LPN</th>            <td>   -1.2149</td> <td>    0.088</td> <td>  -13.783</td> <td> 0.000</td> <td>   -1.388</td> <td>   -1.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_STNA</th>               <td>   -0.7624</td> <td>    0.100</td> <td>   -7.587</td> <td> 0.000</td> <td>   -0.959</td> <td>   -0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>segmentName_d</th>           <td>   -0.7510</td> <td>    0.057</td> <td>  -13.153</td> <td> 0.000</td> <td>   -0.863</td> <td>   -0.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_pay</th>                 <td>    0.0248</td> <td>    0.003</td> <td>    8.943</td> <td> 0.000</td> <td>    0.019</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_Austin</th>         <td>   -0.9878</td> <td>    0.086</td> <td>  -11.515</td> <td> 0.000</td> <td>   -1.156</td> <td>   -0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_Cincinnati</th>     <td>   -0.4282</td> <td>    0.239</td> <td>   -1.788</td> <td> 0.074</td> <td>   -0.898</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_DFW</th>            <td>   -0.9977</td> <td>    0.066</td> <td>  -15.065</td> <td> 0.000</td> <td>   -1.128</td> <td>   -0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_Houston</th>        <td>   -1.2084</td> <td>    0.059</td> <td>  -20.343</td> <td> 0.000</td> <td>   -1.325</td> <td>   -1.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_Northeast Ohio</th> <td>   -0.7928</td> <td>    0.095</td> <td>   -8.335</td> <td> 0.000</td> <td>   -0.979</td> <td>   -0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_prev_SA</th>           <td>   -0.0009</td> <td>    0.001</td> <td>   -1.115</td> <td> 0.265</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_prev_CW</th>           <td>    0.0441</td> <td>    0.013</td> <td>    3.277</td> <td> 0.001</td> <td>    0.018</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_CNA</th>                <td>   -0.6598</td> <td>    0.057</td> <td>  -11.510</td> <td> 0.000</td> <td>   -0.772</td> <td>   -0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reliability_score</th>       <td>   -0.0003</td> <td>    0.000</td> <td>   -0.914</td> <td> 0.361</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                54897\n",
       "Model:                          Logit   Df Residuals:                    54880\n",
       "Method:                           MLE   Df Model:                           16\n",
       "Date:                Mon, 07 Jun 2021   Pseudo R-squ.:                 0.03460\n",
       "Time:                        16:46:03   Log-Likelihood:                -14318.\n",
       "converged:                       True   LL-Null:                       -14831.\n",
       "Covariance Type:            nonrobust   LLR p-value:                2.720e-208\n",
       "===========================================================================================\n",
       "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "prev_CW/SA_rate             2.3308      0.201     11.584      0.000       1.936       2.725\n",
       "U_approve2now              -0.0469      0.003    -17.046      0.000      -0.052      -0.042\n",
       "prev_CW x SA_rate           0.0001   2.32e-05      4.565      0.000    6.05e-05       0.000\n",
       "type_RN                    -2.5319      0.143    -17.734      0.000      -2.812      -2.252\n",
       "type_LVN+LPN               -1.2149      0.088    -13.783      0.000      -1.388      -1.042\n",
       "type_STNA                  -0.7624      0.100     -7.587      0.000      -0.959      -0.565\n",
       "segmentName_d              -0.7510      0.057    -13.153      0.000      -0.863      -0.639\n",
       "net_pay                     0.0248      0.003      8.943      0.000       0.019       0.030\n",
       "areaName_Austin            -0.9878      0.086    -11.515      0.000      -1.156      -0.820\n",
       "areaName_Cincinnati        -0.4282      0.239     -1.788      0.074      -0.898       0.041\n",
       "areaName_DFW               -0.9977      0.066    -15.065      0.000      -1.128      -0.868\n",
       "areaName_Houston           -1.2084      0.059    -20.343      0.000      -1.325      -1.092\n",
       "areaName_Northeast Ohio    -0.7928      0.095     -8.335      0.000      -0.979      -0.606\n",
       "count_prev_SA              -0.0009      0.001     -1.115      0.265      -0.003       0.001\n",
       "count_prev_CW               0.0441      0.013      3.277      0.001       0.018       0.070\n",
       "type_CNA                   -0.6598      0.057    -11.510      0.000      -0.772      -0.547\n",
       "reliability_score          -0.0003      0.000     -0.914      0.361      -0.001       0.000\n",
       "===========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logit summary\n",
    "import statsmodels.api as sm\n",
    "smlogit = sm.Logit(y_train,X_train).fit()\n",
    "smlogit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting? No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34462 16235]\n",
      " [ 1459  2741]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.68      0.80     50697\n",
      "           1       0.14      0.65      0.24      4200\n",
      "\n",
      "    accuracy                           0.68     54897\n",
      "   macro avg       0.55      0.67      0.52     54897\n",
      "weighted avg       0.90      0.68      0.75     54897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45939  4758]\n",
      " [ 2849  1351]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     50697\n",
      "           1       0.22      0.32      0.26      4200\n",
      "\n",
      "    accuracy                           0.86     54897\n",
      "   macro avg       0.58      0.61      0.59     54897\n",
      "weighted avg       0.89      0.86      0.87     54897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test threshold\n",
    "limiter = higher_limiter\n",
    "\n",
    "y_prob = list(logit.predict_proba(X_train)[:,1])\n",
    "y_pred = []\n",
    "count =0\n",
    "for prob in y_prob:\n",
    "    if prob >= limiter:\n",
    "        y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[813 105]\n",
      " [ 42  40]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       918\n",
      "           1       0.28      0.49      0.35        82\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.61      0.69      0.63      1000\n",
      "weighted avg       0.90      0.85      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test threshold\n",
    "limiter = higher_limiter\n",
    "\n",
    "y_prob = list(logit.predict_proba(x_valid)[:,1])\n",
    "y_pred = []\n",
    "count = 0\n",
    "for prob in y_prob:\n",
    "    if prob >= limiter:\n",
    "        y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The limiter we adopt is 0.657\n",
      "By covering 0.145 labeled as high probability of UCW, we have prepared for 0.488 of real UCW\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "label_coverage = y_pred.count(1)/len(y_pred)\n",
    "UCW_coverage = recall_score(y_valid, y_pred)\n",
    "\n",
    "print('The limiter we adopt is %.3f' % (limiter))\n",
    "print('By covering %.3f labeled as high probability of UCW, we have prepared for %.3f of real UCW' \n",
    "      % (label_coverage,UCW_coverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit real data in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input\n",
    "real_X = realdata.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concat predicted prob with data\n",
    "realdata['prob'] = list(logit.predict_proba(real_X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80717</th>\n",
       "      <td>199102</td>\n",
       "      <td>2021-06-09 05:00:00</td>\n",
       "      <td>0.636987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80537</th>\n",
       "      <td>198788</td>\n",
       "      <td>2021-06-09 05:00:00</td>\n",
       "      <td>0.555280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80732</th>\n",
       "      <td>199129</td>\n",
       "      <td>2021-06-09 05:00:00</td>\n",
       "      <td>0.490924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80549</th>\n",
       "      <td>198805</td>\n",
       "      <td>2021-06-09 05:00:00</td>\n",
       "      <td>0.572149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79762</th>\n",
       "      <td>197341</td>\n",
       "      <td>2021-06-09 05:00:00</td>\n",
       "      <td>0.490933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          Start_Time      prob\n",
       "80717  199102 2021-06-09 05:00:00  0.636987\n",
       "80537  198788 2021-06-09 05:00:00  0.555280\n",
       "80732  199129 2021-06-09 05:00:00  0.490924\n",
       "80549  198805 2021-06-09 05:00:00  0.572149\n",
       "79762  197341 2021-06-09 05:00:00  0.490933"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record when this prediction is ran\n",
    "from datetime import date\n",
    "time = str(date.today().year) + '-' + str(date.today().month) + '-' + str(date.today().day)\n",
    "limiter = round(limiter,2)\n",
    "realdata[['id', 'Start_Time', 'prob']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob = realdata[['id', 'Start_Time', 'prob']][realdata['prob'] > limiter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append newly processed data to prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# specify connection to database\n",
    "import psycopg2\n",
    "connection = psycopg2.connect(\n",
    "    host=\"nursedash-prod.cuzi2kducsnv.us-east-1.rds.amazonaws.com\",\n",
    "    database=\"nursedash\",\n",
    "    user=\"external_analyst\",\n",
    "    password=\"vWHYpF9CNtC9KWBG7sZ5JvX9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> all time to chicago time, No withdrawn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT  sa.id, sa.user_id, sa.shift_id, f.id AS facility_id, sa.\"withdrawnInfo\" -> 'initiator' as withdrawnInfo_value,\n",
    "sa.\"status\", sa.\"prevStatus\", sa.\"distance\", s.\"facility_id\", \"s\".\"description\" AS \"shift_description\",\n",
    "\"s\".\"assigned_nurse_id\", s.\"net_pay\", \"s\".\"unit\" AS \"s_unit\",s.\"type\",\n",
    "\"s\".\"qualifications\" AS \"s_qualifications\", \"s\".\"breakTime\" AS \"s_breakTime\", sa.\"withdrawnInfo\",\n",
    "\"f\".\"name\" AS \"facility_name\",\"f\".\"short_name\" AS \"f_short_name\", f.\"segmentName\", f.\"areaName\",\n",
    "timezone('America/Chicago', s.\"createdAt\") as s_create,\n",
    "timezone('America/Chicago', sa.\"createdAt\") as sa_create,\n",
    "timezone('America/Chicago', u.\"approvedAt\") as u_approve,\n",
    "timezone('America/Chicago', u.\"createdAt\") as u_create,\n",
    "timezone('America/Chicago', sa.\"statusUpdatedAt\") as sa_statusUpdate,\n",
    "timezone('America/Chicago', timezone('UTC', s.start_time)) AS \"Start_Time\" \n",
    "FROM shifts s\n",
    "INNER JOIN shift_applications sa ON s.id = sa.shift_id\n",
    "INNER JOIN facilities f ON s.facility_id = f.id\n",
    "INNER JOIN users u ON sa.user_id = u.id\n",
    "\n",
    "\"\"\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'facility_id', 'withdrawninfo_value',\n",
       "       'status', 'prevStatus', 'distance', 'facility_id', 'shift_description',\n",
       "       'assigned_nurse_id', 'net_pay', 's_unit', 'type', 's_qualifications',\n",
       "       's_breakTime', 'withdrawnInfo', 'facility_name', 'f_short_name',\n",
       "       'segmentName', 'areaName', 's_create', 'sa_create', 'u_approve',\n",
       "       'u_create', 'sa_statusupdate', 'Start_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_day(hour):\n",
    "    return (\n",
    "        \"morning\" if 4 < hour <= 12\n",
    "        else\n",
    "        \"afternoon\" if 12 < hour <= 17\n",
    "        else\n",
    "        \"evening/night\" if 18 < hour <= 22\n",
    "        else\n",
    "        \"overnight\"\n",
    "\n",
    "    )\n",
    "\n",
    "df['Start_time_of_the_day'] = df.apply(lambda row: get_part_of_day(row['Start_Time'].hour), axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine the prediction file with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the prediction file\n",
    "prediction = realdata[['id', 'Start_Time', 'prob']]\n",
    "validation = prediction.merge(df, on = 'id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# convert to datetime for conditonal selection\n",
    "validation['Start_Time_x'] = pd.to_datetime(validation['Start_Time_x'])\n",
    "\n",
    "# only select date part of the time\n",
    "validation['Start_Time_x'] = validation.apply(lambda row: str(row['Start_Time_x'].date()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename start time\n",
    "validation = validation.rename(columns={\"Start_Time_x\": \"Start_Time\"})\n",
    "\n",
    "# limit our result to what we want as validation file\n",
    "validation = validation[['id','prob','Start_Time','Start_time_of_the_day','status','type','prevStatus','areaName','segmentName','facility_name','user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prob', 'Start_Time', 'Start_time_of_the_day', 'status', 'type',\n",
       "       'prevStatus', 'areaName', 'segmentName', 'facility_name', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = validation.set_index(\"id\")\n",
    "validation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.to_csv('pred_{}_Silver_Bullet.csv'.format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>Start_time_of_the_day</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "      <th>prevStatus</th>\n",
       "      <th>areaName</th>\n",
       "      <th>segmentName</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199102</th>\n",
       "      <td>0.636987</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LPN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Macedonia</td>\n",
       "      <td>10048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198788</th>\n",
       "      <td>0.555280</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LPN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Macedonia</td>\n",
       "      <td>16041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199129</th>\n",
       "      <td>0.490924</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LPN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Broadview Heights</td>\n",
       "      <td>19664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198805</th>\n",
       "      <td>0.572149</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Broadview Heights</td>\n",
       "      <td>16536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197341</th>\n",
       "      <td>0.490933</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at North Ridgeville</td>\n",
       "      <td>17061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191649</th>\n",
       "      <td>0.104154</td>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>RN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Woodlands Specialty Hospital</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192531</th>\n",
       "      <td>0.772450</td>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192145</th>\n",
       "      <td>0.447694</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>4733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192532</th>\n",
       "      <td>0.772439</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>CareCore at Willowood</td>\n",
       "      <td>9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191650</th>\n",
       "      <td>0.104002</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>RN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Woodlands Specialty Hospital</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1119 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prob  Start_Time Start_time_of_the_day     status  type  \\\n",
       "id                                                                    \n",
       "199102  0.636987  2021-06-09               morning  confirmed   LPN   \n",
       "198788  0.555280  2021-06-09               morning  confirmed   LPN   \n",
       "199129  0.490924  2021-06-09               morning  confirmed   LPN   \n",
       "198805  0.572149  2021-06-09               morning  confirmed  STNA   \n",
       "197341  0.490933  2021-06-09               morning  confirmed  STNA   \n",
       "...          ...         ...                   ...        ...   ...   \n",
       "191649  0.104154  2021-07-10               morning  confirmed    RN   \n",
       "192531  0.772450  2021-07-10             afternoon  confirmed  STNA   \n",
       "192145  0.447694  2021-07-11             afternoon  confirmed  STNA   \n",
       "192532  0.772439  2021-07-11             afternoon  confirmed  STNA   \n",
       "191650  0.104002  2021-07-12               morning  confirmed    RN   \n",
       "\n",
       "       prevStatus        areaName    segmentName  \\\n",
       "id                                                 \n",
       "199102   selected  Northeast Ohio  Senior Living   \n",
       "198788   selected  Northeast Ohio  Senior Living   \n",
       "199129   selected  Northeast Ohio  Senior Living   \n",
       "198805   selected  Northeast Ohio  Senior Living   \n",
       "197341   selected  Northeast Ohio  Senior Living   \n",
       "...           ...             ...            ...   \n",
       "191649   selected         Houston     Healthcare   \n",
       "192531   selected  Northeast Ohio  Senior Living   \n",
       "192145   selected  Northeast Ohio  Senior Living   \n",
       "192532   selected  Northeast Ohio  Senior Living   \n",
       "191650   selected         Houston     Healthcare   \n",
       "\n",
       "                       facility_name  user_id  \n",
       "id                                             \n",
       "199102           Avenue at Macedonia    10048  \n",
       "198788           Avenue at Macedonia    16041  \n",
       "199129   Avenue at Broadview Heights    19664  \n",
       "198805   Avenue at Broadview Heights    16536  \n",
       "197341    Avenue at North Ridgeville    17061  \n",
       "...                              ...      ...  \n",
       "191649  Woodlands Specialty Hospital     7894  \n",
       "192531         CareCore at Willowood     9428  \n",
       "192145         CareCore at Willowood     4733  \n",
       "192532         CareCore at Willowood     9428  \n",
       "191650  Woodlands Specialty Hospital     7894  \n",
       "\n",
       "[1119 rows x 10 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation#.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only northeast ohio and stna, and make a pivot table\n",
    "# create a column called count\n",
    "pivot_table = validation[(validation['areaName'] == 'Northeast Ohio') & \n",
    "           (validation['type'] == 'STNA') & (validation['prob'] > 0.55)].groupby([\"Start_Time\",\n",
    "                                    \"Start_time_of_the_day\"]).size().reset_index(name='count').set_index(\"Start_Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the count is above limiter of 5\n",
    "# pivot_table['above_limiter'] = pivot_table.apply(lambda row: 2 if row['count'] >= 5 else 0, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_time_of_the_day</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-09</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-09</th>\n",
       "      <td>morning</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-09</th>\n",
       "      <td>overnight</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-10</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-10</th>\n",
       "      <td>morning</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-10</th>\n",
       "      <td>overnight</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <td>morning</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <td>overnight</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-12</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-12</th>\n",
       "      <td>morning</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-12</th>\n",
       "      <td>overnight</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-13</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-13</th>\n",
       "      <td>morning</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-13</th>\n",
       "      <td>overnight</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-14</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-14</th>\n",
       "      <td>morning</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-14</th>\n",
       "      <td>overnight</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-15</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-15</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Start_time_of_the_day  count\n",
       "Start_Time                             \n",
       "2021-06-09             afternoon      4\n",
       "2021-06-09               morning      8\n",
       "2021-06-09             overnight      4\n",
       "2021-06-10             afternoon      5\n",
       "2021-06-10               morning      5\n",
       "2021-06-10             overnight      4\n",
       "2021-06-11             afternoon      2\n",
       "2021-06-11               morning      8\n",
       "2021-06-11             overnight      5\n",
       "2021-06-12             afternoon      1\n",
       "2021-06-12               morning      8\n",
       "2021-06-12             overnight      6\n",
       "2021-06-13             afternoon      2\n",
       "2021-06-13               morning      5\n",
       "2021-06-13             overnight      5\n",
       "2021-06-14             afternoon      2\n",
       "2021-06-14               morning      7\n",
       "2021-06-14             overnight      4\n",
       "2021-06-15             afternoon      1\n",
       "2021-06-15               morning      1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.to_excel(\"plan2_pred_{}.xlsx\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
