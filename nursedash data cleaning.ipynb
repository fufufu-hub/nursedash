{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target- urgent withdrawn by nurse(within 24hr)\n",
    "* shift_applications status == 'cancelled' + shift_application prevStatus == 'confirmed'\n",
    "\n",
    "\n",
    "### IDs -> only look at shifts application, leave each shifts after\n",
    "* shift_applications id\n",
    "* shift_applications user_id\n",
    "* shift_applications shift_id\n",
    "\n",
    "\n",
    "### Numeric Field\n",
    "* shifts rate\n",
    "* shifts net_pay: rate - nursedash profit\n",
    "* shift_applications distance\n",
    "* shift break time\n",
    "* user withdrawn times: \n",
    "    Problem: \n",
    "        1. We don't know in reality that you will withdraw your previous one.\n",
    "        2. cannot be used to predict new user\n",
    "* user applied times:\n",
    "* prev SA/CW rate\n",
    "\n",
    "\n",
    "## Time\n",
    "### shift, shift app time\n",
    "* S_Create (shift created) => SA_Create (application created) => CWTime (comfim withdrawn) => Start_Time (shift start)\n",
    "* S_Create: shift create time\n",
    "* SA_Create: shift application create time\n",
    "* CWTime: shift withdrawn time, whole confirmed withdrawn population (include within 24hr and > 24hr)\n",
    "* Start_Time: shift start time\n",
    "##### calculated field, graph in hours\n",
    "* S_Create2SA_Create: shift application create time - shift create time\n",
    "* S_Create2Start_Time: shift start time - shift create time\n",
    "        1. has negative values. delete maybe?\n",
    "* SA_Create2Start_Time: shift start time - shift application create time\n",
    "        1. has negative values. delete maybe?\n",
    "\n",
    "### User\n",
    "* user approvedAt:\n",
    "* user createdAt:\n",
    "#### Calculated field\n",
    "* U_Create2U_approved: User approve time - User create time\n",
    "* U_Create2now: now - User create time, in months(seconds/2629746)\n",
    "* U_Approve2now: now - User approve time\n",
    "\n",
    "\n",
    "### Categorical\n",
    "* shifts role: position name + type\n",
    "* facilities name = facilities short_name\n",
    "* facilities areaId = facilities areaName\n",
    "* withdrawnInfo_key, withdrawnInfo_value\n",
    "* facilities segmentName: Senior Living = 1, Healthcare = 0\n",
    "* Users enableNotifications:\n",
    "* Users emailNotifications:\n",
    "* Users appNotifications:\n",
    "* Users allowedNotifications:\n",
    "\n",
    "\n",
    "### ?\n",
    "* facilities allowedQualification\n",
    "* facilities createdAt\n",
    "* facilities rates\n",
    "* nurse shift withdrawn by admin, when policy start, how many withdrawn by admin\n",
    "* shifts = unit\n",
    "* role\n",
    "* users updateAt ?\n",
    "* users relationToFacility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB, Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# specify connection to database\n",
    "import psycopg2\n",
    "connection = psycopg2.connect(\n",
    "    host=\"nursedash-prod.cuzi2kducsnv.us-east-1.rds.amazonaws.com\",\n",
    "    database=\"nursedash\",\n",
    "    user=\"external_analyst\",\n",
    "    password=\"uDps8APganhSLc3K2xe7NtMPq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_sql_query(\"\"\"\n",
    "\n",
    "# SELECT sa.user_id, sa.shift_id, sa.id as shift_application_id,\n",
    "# sa.\"createdAt\", \n",
    "# timezone(case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end, timezone('UTC', s.start_time)) as Start_Time, \n",
    "# case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end as timezone,\n",
    "# sa.\"status\", sa.\"prevStatus\",\n",
    "# sa.distance, s.\"description\" as \"shift_description\",\n",
    "# f.id as facility_id, f.name as facility_name,\n",
    "# s.net_pay, s.type\n",
    "# FROM shifts s\n",
    "# INNER JOIN facilities f on s.facility_id = f.id\n",
    "# INNER JOIN shift_applications sa on s.id = sa.shift_id\n",
    "\n",
    "# \"\"\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT  sa.id as shift_application_id, sa.user_id, sa.shift_id, f.id AS facility_id,\n",
    "sa.\"status\", sa.\"prevStatus\", sa.\"distance\", s.\"facility_id\", \"s\".\"description\" AS \"shift_description\",\n",
    "\"s\".\"assigned_nurse_id\", s.\"net_pay\", \"s\".\"unit\" AS \"s_unit\",s.\"type\",\n",
    "\"s\".\"qualifications\" AS \"s_qualifications\", \"s\".\"breakTime\" AS \"s_breakTime\",\n",
    "\"f\".\"name\" AS \"f_name\",\"f\".\"short_name\" AS \"f_short_name\",\n",
    "timezone(case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end, s.\"createdAt\") as s_create,\n",
    "timezone(case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end, sa.\"createdAt\") as sa_create,\n",
    "timezone(case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end, u.\"approvedAt\") as u_approve,\n",
    "timezone(case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end, u.\"createdAt\") as u_create,\n",
    "timezone(case when f.timezone = 'CST' then 'America/Chicago' else f.timezone end, timezone('UTC', s.start_time)) as Start_Time \n",
    "FROM shifts s\n",
    "INNER JOIN shift_applications sa ON s.id = sa.shift_id\n",
    "INNER JOIN facilities f ON s.facility_id = f.id\n",
    "INNER JOIN users u ON sa.user_id = u.id\n",
    "\n",
    "\"\"\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift_application_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>shift_id</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>status</th>\n",
       "      <th>prevStatus</th>\n",
       "      <th>distance</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>shift_description</th>\n",
       "      <th>assigned_nurse_id</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>s_qualifications</th>\n",
       "      <th>s_breakTime</th>\n",
       "      <th>f_name</th>\n",
       "      <th>f_short_name</th>\n",
       "      <th>s_create</th>\n",
       "      <th>sa_create</th>\n",
       "      <th>u_approve</th>\n",
       "      <th>u_create</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>applied</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeking ICU specialty RN's for per-diem and lo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nursedash (Internal)</td>\n",
       "      <td>ND</td>\n",
       "      <td>2018-08-02 09:25:56.428</td>\n",
       "      <td>2018-08-02 09:25:56.624</td>\n",
       "      <td>2020-03-04 12:04:44.254</td>\n",
       "      <td>2018-08-02 09:25:56.300</td>\n",
       "      <td>2017-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>applied</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeking ICU specialty RN's for per-diem and lo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nursedash (Internal)</td>\n",
       "      <td>ND</td>\n",
       "      <td>2018-08-02 09:25:56.428</td>\n",
       "      <td>2018-08-02 09:25:56.624</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-08-02 09:25:56.300</td>\n",
       "      <td>2017-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeking ICU specialty RN's for per-diem and lo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nursedash (Internal)</td>\n",
       "      <td>ND</td>\n",
       "      <td>2018-08-02 09:25:56.428</td>\n",
       "      <td>2018-08-02 09:25:56.624</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-08-02 09:25:56.300</td>\n",
       "      <td>2017-09-12 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>applied</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeking Medical Surgical specialty RN's for pe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nursedash (Internal)</td>\n",
       "      <td>ND</td>\n",
       "      <td>2018-08-02 09:25:56.428</td>\n",
       "      <td>2018-08-02 09:25:56.624</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-08-02 09:25:56.300</td>\n",
       "      <td>2017-09-17 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>applied</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Seeking Medical Surgical specialty RN's for pe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nursedash (Internal)</td>\n",
       "      <td>ND</td>\n",
       "      <td>2018-08-02 09:25:56.428</td>\n",
       "      <td>2018-08-02 09:25:56.624</td>\n",
       "      <td>2020-03-04 12:04:44.254</td>\n",
       "      <td>2018-08-02 09:25:56.300</td>\n",
       "      <td>2017-09-17 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shift_application_id  user_id  shift_id  facility_id     status prevStatus  \\\n",
       "0                    80        4         1            1    applied       None   \n",
       "1                   123        3         1            1    applied       None   \n",
       "2                    46        2         1            1  confirmed       None   \n",
       "3                    69        2         2            1    applied       None   \n",
       "4                    79        4         2            1    applied       None   \n",
       "\n",
       "   distance  facility_id                                  shift_description  \\\n",
       "0       NaN            1  Seeking ICU specialty RN's for per-diem and lo...   \n",
       "1       NaN            1  Seeking ICU specialty RN's for per-diem and lo...   \n",
       "2       NaN            1  Seeking ICU specialty RN's for per-diem and lo...   \n",
       "3       NaN            1  Seeking Medical Surgical specialty RN's for pe...   \n",
       "4       NaN            1  Seeking Medical Surgical specialty RN's for pe...   \n",
       "\n",
       "   assigned_nurse_id  ...  type  s_qualifications s_breakTime  \\\n",
       "0                2.0  ...  None              None         0.0   \n",
       "1                2.0  ...  None              None         0.0   \n",
       "2                2.0  ...  None              None         0.0   \n",
       "3                5.0  ...  None              None         0.0   \n",
       "4                5.0  ...  None              None         0.0   \n",
       "\n",
       "                 f_name  f_short_name                s_create  \\\n",
       "0  Nursedash (Internal)            ND 2018-08-02 09:25:56.428   \n",
       "1  Nursedash (Internal)            ND 2018-08-02 09:25:56.428   \n",
       "2  Nursedash (Internal)            ND 2018-08-02 09:25:56.428   \n",
       "3  Nursedash (Internal)            ND 2018-08-02 09:25:56.428   \n",
       "4  Nursedash (Internal)            ND 2018-08-02 09:25:56.428   \n",
       "\n",
       "                sa_create               u_approve                u_create  \\\n",
       "0 2018-08-02 09:25:56.624 2020-03-04 12:04:44.254 2018-08-02 09:25:56.300   \n",
       "1 2018-08-02 09:25:56.624                     NaT 2018-08-02 09:25:56.300   \n",
       "2 2018-08-02 09:25:56.624                     NaT 2018-08-02 09:25:56.300   \n",
       "3 2018-08-02 09:25:56.624                     NaT 2018-08-02 09:25:56.300   \n",
       "4 2018-08-02 09:25:56.624 2020-03-04 12:04:44.254 2018-08-02 09:25:56.300   \n",
       "\n",
       "            start_time  \n",
       "0  2017-09-12 07:00:00  \n",
       "1  2017-09-12 07:00:00  \n",
       "2  2017-09-12 07:00:00  \n",
       "3  2017-09-17 15:00:00  \n",
       "4  2017-09-17 15:00:00  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7323.284045277778"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta.total_seconds(df_test['u_approve'][0] - df_test['u_create'][0])/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.975228798533397"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timedelta.total_seconds(datetime.now() - df_test['u_create'][0])/2629746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.950037519774153"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "timedelta.total_seconds(datetime.now() - df_test['u_approve'][0])/2629746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.654403068611111"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta.total_seconds(df_test['sa_create'][0] - df_test['s_create'][0])/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.01341621750001"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta.total_seconds(df_test['start_time'][0] - df_test['sa_create'][0])/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172593 entries, 0 to 172592\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   user_id               172593 non-null  int64         \n",
      " 1   shift_id              172593 non-null  int64         \n",
      " 2   shift_application_id  172593 non-null  int64         \n",
      " 3   sa_create             172593 non-null  datetime64[ns]\n",
      " 4   u_approve             172015 non-null  datetime64[ns]\n",
      " 5   u_create              172593 non-null  datetime64[ns]\n",
      " 6   start_time            172593 non-null  object        \n",
      "dtypes: datetime64[ns](3), int64(3), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "'S_create2SA_Create', 'SA_Create2Start_Time', 'S_Create2Start_Time', 'CW_Time2Start_Time',\n",
    "'SA_Create2CW_Time', 'S_Create2CW_Time',\n",
    "'U_create2now', 'U_approve2now', 'U_create2U_approve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT \"sa\".\"id\" AS \"sa.id\",\"sa\".\"user_id\" AS \"sa.user_id\",\"sa\".\"shift_id\" AS \"sa.shift_id\",\"sa\".\"status\" AS \"sa.status\",\"sa\".\"createdAt\" AS \"sa.createdAt\",\n",
    "\"sa\".\"hasBreakTime\" AS \"sa.hasBreakTime\",\"sa\".\"prevStatus\" AS \"sa.prevStatus\",\"sa\".\"distance\" AS \"sa.distance\",\n",
    "\"s1\".\"facility_id\" AS \"s1.facility_id\",\"s1\".\"description\" AS \"s1.description\",\"s1\".\"start_time\" AS \"s1.start_time\",\"s1\".\"assigned_nurse_id\" AS \"s1.assigned_nurse_id\",\n",
    "\"s1\".\"rate\" AS \"s1.rate\",\"s1\".\"net_pay\" AS \"s1.net_pay\",\"s1\".\"unit\" AS \"s1.unit\",\"s1\".\"type\" AS \"s1.type\",\"s1\".\"createdAt\" AS \"s1.createdAt\",\"s1\".\"qualifications\" AS \"s1.qualifications\",\n",
    "\"s1\".\"breakTime\" AS \"s1.breakTime\",\"s1\".\"prevStatus\" AS \"s1.prevStatus\",\"f\".\"id\" AS \"f.id\",\"f\".\"name\" AS \"f.name\",\"f\".\"short_name\" AS \"f.short_name\"\n",
    "FROM \"public\".\"shift_applications\" AS \"sa\"\n",
    "LEFT JOIN \"public\".\"shifts\" AS \"s1\" ON \"sa\".\"shift_id\" = \"s1\".\"id\"\n",
    "LEFT JOIN \"public\".\"facilities\" AS \"f\" ON \"s1\".\"facility_id\" = \"f\".\"id\"\n",
    "LEFT JOIN \"public\".\"users\" AS \"u\" ON \"sa\".\"user_id\" = \"u\".\"id\"\n",
    "\n",
    "\"\"\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'status', 'createdAt',\n",
       "       'hasNurseCheckEvent', 'hasBreakTime', 'prevStatus', 'distance', 'id.1',\n",
       "       'facility_id', 'description', 'start_time', 'assigned_nurse_id', 'rate',\n",
       "       'net_pay', 'unit', 'type', 'createdAt.1', 'qualifications', 'breakTime',\n",
       "       'prevStatus.1', 'id.2', 'name', 'short_name', 'createdAt.2', 'rates',\n",
       "       'S_Create', 'SA_Create', 'S_create2SA_Create', 'Start_Time',\n",
       "       'SA_Create2Start_Time', 'S_Create2Start_Time', 'CW_Time',\n",
       "       'CW_Time2Start_Time', 'SA_Create2CW_Time', 'S_Create2CW_Time',\n",
       "       'allowedQualifications', 'areaId', 'areaName', 'segmentName',\n",
       "       'U_create2now', 'U_approve2now', 'U_create2U_approve',\n",
       "       'withdrawnInfo_key', 'withdrawnInfo_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('main.csv').drop(columns = ['Unnamed: 0'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill these column with 0, no cw make these column nan\n",
    "df[['CW_Time', 'SA_Create2CW_Time', 'S_Create2CW_Time']] = df[['CW_Time', 'SA_Create2CW_Time', 'S_Create2CW_Time']].fillna(0)\n",
    "\n",
    "# There are some negative numbers in these column. Target all = 0, drop for now\n",
    "df = df[(df[\"S_Create2Start_Time\"]>0) & (df[\"SA_Create2Start_Time\"]>0)]\n",
    "\n",
    "# sort by time that shift was created\n",
    "df = df.sort_values(by = 'createdAt').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selected       34689\n",
       "unavailable       10\n",
       "applied            1\n",
       "cancelled          1\n",
       "Name: prevStatus, dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are prevstatus column like when status = confirmed\n",
    "df[df['status'] == 'confirmed']['prevStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "withdrawn    25020\n",
       "cancelled     6231\n",
       "applied          1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are status column like when prevstatus = confirmed\n",
    "df[df['prevStatus'] == 'confirmed']['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: urgent withdrawn as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CW_by_nurse(row):\n",
    "    if row['status']=='withdrawn' and row['prevStatus'] == 'confirmed':\n",
    "        if row['withdrawnInfo_value'] == 'nurse':\n",
    "            if row['CW_Time2Start_Time'] < 0 and row['CW_Time2Start_Time'] >= -24:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['target'] = df.apply (lambda row: CW_by_nurse(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    161819\n",
       "1      4338\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Count previsous shift application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track by using dictionary\n",
    "count_prev_SA = []\n",
    "test = df[['user_id', 'createdAt']]\n",
    "\n",
    "# create SA dictionary, set all value = 0 -> dramatically reduce computational cost\n",
    "uid_library = list(pd.unique(test['user_id']))\n",
    "sa_dict = {} \n",
    "for uid in uid_library:\n",
    "    sa_dict.update({uid: 0}) \n",
    "    \n",
    "for i, v in enumerate(test['user_id']):\n",
    "    sa_dict[v] += 1\n",
    "    count_prev_SA.append(sa_dict[v]-1)\n",
    " \n",
    "df['count_prev_SA'] = count_prev_SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Count previsous urgent withdrawns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track by using dictionary\n",
    "count_prev_CW = []\n",
    "test = df[['user_id', 'count_prev_SA', 'createdAt', 'target']]\n",
    "\n",
    "# create cw dictionary, set all value = 0 -> dramatically reduce computational cost\n",
    "uid_library = list(pd.unique(test['user_id']))\n",
    "cw_dict = {} \n",
    "for uid in uid_library:\n",
    "    cw_dict.update({uid: 0}) \n",
    "    \n",
    "# fill dictionary and fill cw count\n",
    "for i, v in enumerate(test['user_id']):\n",
    "    if test['target'][i] == 1:\n",
    "        cw_dict[v] += 1\n",
    "        count_prev_CW.append(cw_dict[v]-1)\n",
    "    else:\n",
    "        count_prev_CW.append(cw_dict[v])\n",
    "        \n",
    "df['count_prev_CW'] = count_prev_CW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count previsous urgent withdrawns/Count previsous shift applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_CW/SA_rate'] = df['count_prev_CW']/df['count_prev_SA']\n",
    "\n",
    "# fill nan with 0, happend bc 0/0, meaning rate = 0\n",
    "df['prev_CW/SA_rate'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous withdrawn times previous apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_CW x SA_rate'] = df['count_prev_CW']*df['count_prev_SA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Type dummy: RN, LVN + LPN , Rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNA             85316\n",
       "STNA            39643\n",
       "LVN             15695\n",
       "RN              11689\n",
       "LPN              6652\n",
       "CMA/Med-Tech     6238\n",
       "Tech              924\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type_RN'] = df.apply(lambda row:1 if row['type'] == 'RN' else 0, axis = 1)\n",
    "df['type_LVN+LPN'] = df.apply(lambda row: 1 if row['type'] == 'LVN' or row['type'] == 'LPN' else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 SegementName dummy: Senior Living, Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Senior Living    145625\n",
       "Healthcare        20517\n",
       "Name: segmentName, dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['segmentName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmentName_dummy(row):\n",
    "    if row['segmentName']=='Senior Living':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['segmentName_d'] = df.apply(lambda row: create_segmentName_dummy(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Facility Area Name Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Houston           83626\n",
       "Northeast Ohio    46539\n",
       "DFW               26611\n",
       "Austin             5959\n",
       "San Antonio        3302\n",
       "Cincinnati          120\n",
       "Name: areaName, dtype: int64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['areaName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Houston\n",
    "df['areaName_houston'] = df.apply(lambda row: 1 if row['areaName'] == 'Houston' else 0, axis = 1)\n",
    "\n",
    "# Northeast Ohio\n",
    "df['areaName_no'] = df.apply(lambda row: 1 if row['areaName'] == 'Northeast Ohio' else 0, axis = 1)\n",
    "\n",
    "# DFW\n",
    "df['areaName_dfw'] = df.apply(lambda row: 1 if row['areaName'] == 'DFW' else 0, axis = 1)\n",
    "\n",
    "# Austin\n",
    "df['areaName_austin'] = df.apply(lambda row: 1 if row['areaName'] == 'Austin' else 0, axis = 1)\n",
    "\n",
    "# San Antonio\n",
    "df['areaName_san'] = df.apply(lambda row: 1 if row['areaName'] == 'San Antonio' else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue>keep only prevstatus or status = confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.apply(lambda row: (row['prevStatus'] == 'confirmed') or (row['status'] == 'confirmed'), axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green>output feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'status', 'createdAt',\n",
       "       'hasNurseCheckEvent', 'hasBreakTime', 'prevStatus', 'distance', 'id.1',\n",
       "       'facility_id', 'description', 'start_time', 'assigned_nurse_id', 'rate',\n",
       "       'net_pay', 'unit', 'type', 'createdAt.1', 'qualifications', 'breakTime',\n",
       "       'prevStatus.1', 'id.2', 'name', 'short_name', 'createdAt.2', 'rates',\n",
       "       'S_Create', 'SA_Create', 'S_create2SA_Create', 'Start_Time',\n",
       "       'SA_Create2Start_Time', 'S_Create2Start_Time', 'CW_Time',\n",
       "       'CW_Time2Start_Time', 'SA_Create2CW_Time', 'S_Create2CW_Time',\n",
       "       'allowedQualifications', 'areaId', 'areaName', 'segmentName',\n",
       "       'U_create2now', 'U_approve2now', 'U_create2U_approve',\n",
       "       'withdrawnInfo_key', 'withdrawnInfo_value', 'target', 'count_prev_SA',\n",
       "       'count_prev_CW', 'prev_CW/SA_rate', 'prev_CW x SA_rate', 'type_RN',\n",
       "       'type_LVN+LPN', 'segmentName_d', 'areaName_houston', 'areaName_no',\n",
       "       'areaName_dfw', 'areaName_austin', 'areaName_san'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = df[['id', 'user_id', 'shift_id', 'prev_CW/SA_rate', 'status', 'S_create2SA_Create',\n",
    "                 'S_Create2Start_Time',\n",
    "                 'SA_Create2Start_Time','U_create2now', 'U_approve2now','prev_CW x SA_rate', 'type_RN', \n",
    "                 'type_LVN+LPN', 'segmentName_d', 'areaName_houston', 'areaName_no', 'areaName_dfw', \n",
    "                 'areaName_austin', 'areaName_san', 'net_pay', 'distance','target', 'createdAt', 'Start_Time']]\n",
    "feature_df.to_csv('model_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
