{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('model_data.csv').drop(columns = ['Unnamed: 0','f_highrate','f_lowrate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'prev_CW/SA_rate', 'status',\n",
       "       'S_create2SA_Create', 'S_Create2Start_Time', 'SA_Create2Start_Time',\n",
       "       'U_create2now', 'U_approve2now', 'prev_CW x SA_rate', 'type_RN',\n",
       "       'type_LVN+LPN', 'type_STNA', 'segmentName_d', 'areaName_houston',\n",
       "       'areaName_no', 'areaName_dfw', 'areaName_austin', 'areaName_san',\n",
       "       'net_pay', 'target', 'sa_create', 'Start_Time', 'CW_in_a_month',\n",
       "       'count_prev_SA', 'count_prev_CW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice df by the end of this week, for predcition output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import date\n",
    "end_of_week = str(date.today().year) + '-' + str(date.today().month) + '-' + str(date.today().day+1)\n",
    "\n",
    "# convert to datetime for conditonal selection\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "# sort by start time -> for slicing\n",
    "df = df.sort_values(by = 'Start_Time') \n",
    "# record as realdata\n",
    "realdata = df[df['Start_Time'].apply(lambda x: x > pd.to_datetime(end_of_week))]\n",
    "# record predction output rows, don't include it in tran test validation\n",
    "realdata_len = realdata.shape[0]\n",
    "# only keep status = confirmed\n",
    "realdata = realdata[realdata['status'] == 'confirmed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set: 1000 recently records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    915\n",
       "1     85\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice, dont include realdata\n",
    "validation = df[-1000-realdata_len : -realdata_len]\n",
    "\n",
    "y_valid = validation['target']\n",
    "x_valid = validation.drop(['id','user_id', 'shift_id', 'status', 'sa_create', 'Start_Time', 'target'], axis = 1)\n",
    "\n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test: main dataset - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-1000-realdata_len] # slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)\n",
    "y = df['target']\n",
    "\n",
    "# set test, train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make experienment dataset\n",
    "df1 = df[(df['areaName_no'] == 1) & (df['type_STNA']==1)]\n",
    "X_exp = df1.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)\n",
    "y_exp = df1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    67463\n",
       "1     5560\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=100000)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "# assign less punlishment for classifying 0 as 1 -> find more 1's\n",
    "# weights = {0:1, 1:10}\n",
    "# class_weight = 'balanced': automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "logit = LogisticRegression(solver = 'lbfgs', max_iter=100000, class_weight = 'balanced')\n",
    "logit.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13572  6674]\n",
      " [  571  1090]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.67      0.79     20246\n",
      "           1       0.14      0.66      0.23      1661\n",
      "\n",
      "    accuracy                           0.67     21907\n",
      "   macro avg       0.55      0.66      0.51     21907\n",
      "weighted avg       0.90      0.67      0.75     21907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = logit.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.555212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "\n",
    "# predict probabilities\n",
    "yhat = logit.predict_proba(X_exp)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_exp,yhat)\n",
    "\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "\n",
    "lower_limiter = thresholds[ix]\n",
    "print('Best Threshold=%f' % (lower_limiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold=0.657\n"
     ]
    }
   ],
   "source": [
    "# search thresholds for imbalanced classification\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "# predict probabilities\n",
    "yhat = logit.predict_proba(X_exp)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:, 1]\n",
    "# define thresholds\n",
    "thresholds = arange(0, 1, 0.001)\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_exp, to_labels(probs, t)) for t in thresholds]\n",
    "# get best threshold\n",
    "ix = argmax(scores)\n",
    "\n",
    "higher_limiter = thresholds[ix]\n",
    "\n",
    "print('Best threshold=%.3f' % (higher_limiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cf_matrix import make_confusion_matrix\n",
    "# labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "# categories = ['Zero', 'One']\n",
    "# make_confusion_matrix(confusion_matrix(y_test, y_pred), \n",
    "#                       group_names=labels,\n",
    "#                       categories=categories, \n",
    "#                       cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.248365\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ricardolu/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>target</td>      <th>  No. Observations:  </th>  <td> 51116</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 51096</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 24 May 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.07871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:58:54</td>     <th>  Log-Likelihood:    </th> <td> -12695.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -13780.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prev_CW/SA_rate</th>      <td>    2.0787</td> <td>    0.221</td> <td>    9.386</td> <td> 0.000</td> <td>    1.645</td> <td>    2.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_create2SA_Create</th>   <td>    0.0010</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_Create2Start_Time</th>  <td>   -0.0010</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SA_Create2Start_Time</th> <td>   -0.0012</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>U_create2now</th>         <td>    0.0057</td> <td>    0.006</td> <td>    0.878</td> <td> 0.380</td> <td>   -0.007</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>U_approve2now</th>        <td>   -0.0277</td> <td>    0.007</td> <td>   -3.724</td> <td> 0.000</td> <td>   -0.042</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prev_CW x SA_rate</th>    <td>    0.0001</td> <td> 2.66e-05</td> <td>    4.933</td> <td> 0.000</td> <td> 7.92e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_RN</th>              <td>   -3.5285</td> <td>    0.159</td> <td>  -22.237</td> <td> 0.000</td> <td>   -3.840</td> <td>   -3.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_LVN+LPN</th>         <td>   -1.6249</td> <td>    0.084</td> <td>  -19.411</td> <td> 0.000</td> <td>   -1.789</td> <td>   -1.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_STNA</th>            <td>   -0.6029</td> <td>    0.089</td> <td>   -6.775</td> <td> 0.000</td> <td>   -0.777</td> <td>   -0.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>segmentName_d</th>        <td>    0.3837</td> <td>    0.086</td> <td>    4.448</td> <td> 0.000</td> <td>    0.215</td> <td>    0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_houston</th>     <td>   -4.0591</td> <td>    0.125</td> <td>  -32.464</td> <td> 0.000</td> <td>   -4.304</td> <td>   -3.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_no</th>          <td>   -3.5432</td> <td>    0.148</td> <td>  -23.936</td> <td> 0.000</td> <td>   -3.833</td> <td>   -3.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_dfw</th>         <td>   -3.9912</td> <td>    0.135</td> <td>  -29.635</td> <td> 0.000</td> <td>   -4.255</td> <td>   -3.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_austin</th>      <td>   -3.8898</td> <td>    0.148</td> <td>  -26.299</td> <td> 0.000</td> <td>   -4.180</td> <td>   -3.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>areaName_san</th>         <td>   -3.8385</td> <td>    0.146</td> <td>  -26.229</td> <td> 0.000</td> <td>   -4.125</td> <td>   -3.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_pay</th>              <td>    0.1000</td> <td>    0.004</td> <td>   26.329</td> <td> 0.000</td> <td>    0.093</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CW_in_a_month</th>        <td>    0.2466</td> <td>    0.041</td> <td>    5.960</td> <td> 0.000</td> <td>    0.166</td> <td>    0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_prev_SA</th>        <td>   -0.0019</td> <td>    0.000</td> <td>   -7.703</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_prev_CW</th>        <td>    0.0426</td> <td>    0.008</td> <td>    5.118</td> <td> 0.000</td> <td>    0.026</td> <td>    0.059</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   No. Observations:                51116\n",
       "Model:                          Logit   Df Residuals:                    51096\n",
       "Method:                           MLE   Df Model:                           19\n",
       "Date:                Mon, 24 May 2021   Pseudo R-squ.:                 0.07871\n",
       "Time:                        10:58:54   Log-Likelihood:                -12695.\n",
       "converged:                      False   LL-Null:                       -13780.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "prev_CW/SA_rate          2.0787      0.221      9.386      0.000       1.645       2.513\n",
       "S_create2SA_Create       0.0010        nan        nan        nan         nan         nan\n",
       "S_Create2Start_Time     -0.0010        nan        nan        nan         nan         nan\n",
       "SA_Create2Start_Time    -0.0012        nan        nan        nan         nan         nan\n",
       "U_create2now             0.0057      0.006      0.878      0.380      -0.007       0.018\n",
       "U_approve2now           -0.0277      0.007     -3.724      0.000      -0.042      -0.013\n",
       "prev_CW x SA_rate        0.0001   2.66e-05      4.933      0.000    7.92e-05       0.000\n",
       "type_RN                 -3.5285      0.159    -22.237      0.000      -3.840      -3.217\n",
       "type_LVN+LPN            -1.6249      0.084    -19.411      0.000      -1.789      -1.461\n",
       "type_STNA               -0.6029      0.089     -6.775      0.000      -0.777      -0.428\n",
       "segmentName_d            0.3837      0.086      4.448      0.000       0.215       0.553\n",
       "areaName_houston        -4.0591      0.125    -32.464      0.000      -4.304      -3.814\n",
       "areaName_no             -3.5432      0.148    -23.936      0.000      -3.833      -3.253\n",
       "areaName_dfw            -3.9912      0.135    -29.635      0.000      -4.255      -3.727\n",
       "areaName_austin         -3.8898      0.148    -26.299      0.000      -4.180      -3.600\n",
       "areaName_san            -3.8385      0.146    -26.229      0.000      -4.125      -3.552\n",
       "net_pay                  0.1000      0.004     26.329      0.000       0.093       0.107\n",
       "CW_in_a_month            0.2466      0.041      5.960      0.000       0.166       0.328\n",
       "count_prev_SA           -0.0019      0.000     -7.703      0.000      -0.002      -0.001\n",
       "count_prev_CW            0.0426      0.008      5.118      0.000       0.026       0.059\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logit summary\n",
    "import statsmodels.api as sm\n",
    "smlogit = sm.Logit(y_train,X_train).fit()\n",
    "smlogit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting? No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31612 15605]\n",
      " [ 1278  2621]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.67      0.79     47217\n",
      "           1       0.14      0.67      0.24      3899\n",
      "\n",
      "    accuracy                           0.67     51116\n",
      "   macro avg       0.55      0.67      0.51     51116\n",
      "weighted avg       0.90      0.67      0.75     51116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42030  5187]\n",
      " [ 2501  1398]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92     47217\n",
      "           1       0.21      0.36      0.27      3899\n",
      "\n",
      "    accuracy                           0.85     51116\n",
      "   macro avg       0.58      0.62      0.59     51116\n",
      "weighted avg       0.89      0.85      0.87     51116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test threshold\n",
    "limiter = higher_limiter\n",
    "\n",
    "y_prob = list(logit.predict_proba(X_train)[:,1])\n",
    "y_pred = []\n",
    "count =0\n",
    "for prob in y_prob:\n",
    "    if prob >= limiter:\n",
    "        y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[718 197]\n",
      " [ 35  50]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86       915\n",
      "           1       0.20      0.59      0.30        85\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.58      0.69      0.58      1000\n",
      "weighted avg       0.89      0.77      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test threshold\n",
    "limiter = higher_limiter\n",
    "\n",
    "y_prob = list(logit.predict_proba(x_valid)[:,1])\n",
    "y_pred = []\n",
    "count =0\n",
    "for prob in y_prob:\n",
    "    if prob >= limiter:\n",
    "        y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The limiter we adopt is 0.657\n",
      "By covering 0.247 labeled as high probability of UCW, we have prepared for 0.588 of real UCW\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "label_coverage = y_pred.count(1)/len(y_pred)\n",
    "UCW_coverage = recall_score(y_valid, y_pred)\n",
    "\n",
    "print('The limiter we adopt is %.3f' % (limiter))\n",
    "print('By covering %.3f labeled as high probability of UCW, we have prepared for %.3f of real UCW' \n",
    "      % (label_coverage,UCW_coverage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit real data in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input\n",
    "real_X = realdata.drop(['id','user_id', 'shift_id', 'status', 'target', 'sa_create', 'Start_Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concat predicted prob with data\n",
    "realdata['prob'] = list(logit.predict_proba(real_X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55460</th>\n",
       "      <td>190132</td>\n",
       "      <td>2021-05-25 05:00:00</td>\n",
       "      <td>0.631839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74319</th>\n",
       "      <td>191733</td>\n",
       "      <td>2021-05-25 05:00:00</td>\n",
       "      <td>0.680283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>188967</td>\n",
       "      <td>2021-05-25 06:00:00</td>\n",
       "      <td>0.572462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59101</th>\n",
       "      <td>190536</td>\n",
       "      <td>2021-05-25 06:00:00</td>\n",
       "      <td>0.696872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61599</th>\n",
       "      <td>190827</td>\n",
       "      <td>2021-05-25 06:00:00</td>\n",
       "      <td>0.374523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          Start_Time      prob\n",
       "55460  190132 2021-05-25 05:00:00  0.631839\n",
       "74319  191733 2021-05-25 05:00:00  0.680283\n",
       "74998  188967 2021-05-25 06:00:00  0.572462\n",
       "59101  190536 2021-05-25 06:00:00  0.696872\n",
       "61599  190827 2021-05-25 06:00:00  0.374523"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record when this prediction is ran\n",
    "from datetime import date\n",
    "time = str(date.today().year) + '-' + str(date.today().month) + '-' + str(date.today().day)\n",
    "limiter = round(limiter,2)\n",
    "realdata[['id', 'Start_Time', 'prob']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55460   2021-05-25 05:00:00\n",
       "74319   2021-05-25 05:00:00\n",
       "74998   2021-05-25 06:00:00\n",
       "59101   2021-05-25 06:00:00\n",
       "61599   2021-05-25 06:00:00\n",
       "                ...        \n",
       "53778   2021-06-27 18:00:00\n",
       "55622   2021-06-27 22:30:00\n",
       "55623   2021-06-28 22:30:00\n",
       "38381   2021-06-29 18:00:00\n",
       "66731   2021-06-30 22:30:00\n",
       "Name: Start_Time, Length: 749, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make the prediction doesn't include today\n",
    "realdata['Start_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob = realdata[['id', 'Start_Time', 'prob']][realdata['prob'] > limiter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append newly processed data to prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# specify connection to database\n",
    "import psycopg2\n",
    "connection = psycopg2.connect(\n",
    "    host=\"nursedash-prod.cuzi2kducsnv.us-east-1.rds.amazonaws.com\",\n",
    "    database=\"nursedash\",\n",
    "    user=\"external_analyst\",\n",
    "    password=\"uDps8APganhSLc3K2xe7NtMPq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> all time to chicago time, No withdrawn info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT  sa.id, sa.user_id, sa.shift_id, f.id AS facility_id, sa.\"withdrawnInfo\" -> 'initiator' as withdrawnInfo_value,\n",
    "sa.\"status\", sa.\"prevStatus\", sa.\"distance\", s.\"facility_id\", \"s\".\"description\" AS \"shift_description\",\n",
    "\"s\".\"assigned_nurse_id\", s.\"net_pay\", \"s\".\"unit\" AS \"s_unit\",s.\"type\",\n",
    "\"s\".\"qualifications\" AS \"s_qualifications\", \"s\".\"breakTime\" AS \"s_breakTime\", sa.\"withdrawnInfo\",\n",
    "\"f\".\"name\" AS \"facility_name\",\"f\".\"short_name\" AS \"f_short_name\", f.\"segmentName\", f.\"areaName\",\n",
    "timezone('America/Chicago', s.\"createdAt\") as s_create,\n",
    "timezone('America/Chicago', sa.\"createdAt\") as sa_create,\n",
    "timezone('America/Chicago', u.\"approvedAt\") as u_approve,\n",
    "timezone('America/Chicago', u.\"createdAt\") as u_create,\n",
    "timezone('America/Chicago', sa.\"statusUpdatedAt\") as sa_statusUpdate,\n",
    "timezone('America/Chicago', timezone('UTC', s.start_time)) AS \"Start_Time\" \n",
    "FROM shifts s\n",
    "INNER JOIN shift_applications sa ON s.id = sa.shift_id\n",
    "INNER JOIN facilities f ON s.facility_id = f.id\n",
    "INNER JOIN users u ON sa.user_id = u.id\n",
    "\n",
    "\"\"\", con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'shift_id', 'facility_id', 'withdrawninfo_value',\n",
       "       'status', 'prevStatus', 'distance', 'facility_id', 'shift_description',\n",
       "       'assigned_nurse_id', 'net_pay', 's_unit', 'type', 's_qualifications',\n",
       "       's_breakTime', 'withdrawnInfo', 'facility_name', 'f_short_name',\n",
       "       'segmentName', 'areaName', 's_create', 'sa_create', 'u_approve',\n",
       "       'u_create', 'sa_statusupdate', 'Start_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_day(hour):\n",
    "    return (\n",
    "        \"morning\" if 4 < hour <= 12\n",
    "        else\n",
    "        \"afternoon\" if 12 < hour <= 17\n",
    "        else\n",
    "        \"evening/night\" if 18 < hour <= 22\n",
    "        else\n",
    "        \"overnight\"\n",
    "\n",
    "    )\n",
    "\n",
    "df['Start_time_of_the_day'] = df.apply(lambda row: get_part_of_day(row['Start_Time'].hour), axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine the prediction file with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the prediction file\n",
    "prediction = realdata[['id', 'Start_Time', 'prob']]\n",
    "validation = prediction.merge(df, on = 'id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# convert to datetime for conditonal selection\n",
    "validation['Start_Time_x'] = pd.to_datetime(validation['Start_Time_x'])\n",
    "\n",
    "# only select date part of the time\n",
    "validation['Start_Time_x'] = validation.apply(lambda row: str(row['Start_Time_x'].date()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename start time\n",
    "validation = validation.rename(columns={\"Start_Time_x\": \"Start_Time\"})\n",
    "\n",
    "# limit our result to what we want as validation file\n",
    "validation = validation[['id','prob','Start_Time','Start_time_of_the_day','status','type','prevStatus','areaName','segmentName','facility_name','user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prob', 'Start_Time', 'Start_time_of_the_day', 'status', 'type',\n",
       "       'prevStatus', 'areaName', 'segmentName', 'facility_name', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = validation.set_index(\"id\")\n",
    "validation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.to_csv('pred_{}_Silver_Bullet.csv'.format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>Start_time_of_the_day</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "      <th>prevStatus</th>\n",
       "      <th>areaName</th>\n",
       "      <th>segmentName</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190132</th>\n",
       "      <td>0.631839</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LPN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Medina</td>\n",
       "      <td>12134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191733</th>\n",
       "      <td>0.680283</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>morning</td>\n",
       "      <td>cancelled</td>\n",
       "      <td>LPN</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Avenue at Broadview Heights</td>\n",
       "      <td>17949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188967</th>\n",
       "      <td>0.572462</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>STNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>The Weils</td>\n",
       "      <td>18857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190536</th>\n",
       "      <td>0.696872</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LVN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Austin Retirement and Nursing Center</td>\n",
       "      <td>12807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190827</th>\n",
       "      <td>0.374523</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>morning</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>CNA</td>\n",
       "      <td>selected</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Carriage Inn Katy</td>\n",
       "      <td>13273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191350</th>\n",
       "      <td>0.100093</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>overnight</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LVN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Brookdale Northwest Hills</td>\n",
       "      <td>11726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187244</th>\n",
       "      <td>0.125801</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>evening/night</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LVN</td>\n",
       "      <td>selected</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>The Hillcrest of North Dallas</td>\n",
       "      <td>12153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187245</th>\n",
       "      <td>0.120247</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>evening/night</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LVN</td>\n",
       "      <td>selected</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>The Hillcrest of North Dallas</td>\n",
       "      <td>12153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188097</th>\n",
       "      <td>0.147520</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>overnight</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LPN</td>\n",
       "      <td>selected</td>\n",
       "      <td>Northeast Ohio</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>Ohio Living Rockynol</td>\n",
       "      <td>9113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186889</th>\n",
       "      <td>0.087583</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>evening/night</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>LVN</td>\n",
       "      <td>selected</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Senior Living</td>\n",
       "      <td>The Hillcrest of North Dallas</td>\n",
       "      <td>14645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>749 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prob  Start_Time Start_time_of_the_day     status  type  \\\n",
       "id                                                                    \n",
       "190132  0.631839  2021-05-25               morning  confirmed   LPN   \n",
       "191733  0.680283  2021-05-25               morning  cancelled   LPN   \n",
       "188967  0.572462  2021-05-25               morning  confirmed  STNA   \n",
       "190536  0.696872  2021-05-25               morning  confirmed   LVN   \n",
       "190827  0.374523  2021-05-25               morning  confirmed   CNA   \n",
       "...          ...         ...                   ...        ...   ...   \n",
       "191350  0.100093  2021-06-27             overnight  confirmed   LVN   \n",
       "187244  0.125801  2021-06-27         evening/night  confirmed   LVN   \n",
       "187245  0.120247  2021-06-28         evening/night  confirmed   LVN   \n",
       "188097  0.147520  2021-06-29             overnight  confirmed   LPN   \n",
       "186889  0.087583  2021-06-30         evening/night  confirmed   LVN   \n",
       "\n",
       "       prevStatus        areaName    segmentName  \\\n",
       "id                                                 \n",
       "190132   selected  Northeast Ohio  Senior Living   \n",
       "191733  confirmed  Northeast Ohio  Senior Living   \n",
       "188967   selected  Northeast Ohio  Senior Living   \n",
       "190536   selected          Austin  Senior Living   \n",
       "190827   selected         Houston  Senior Living   \n",
       "...           ...             ...            ...   \n",
       "191350   selected          Austin  Senior Living   \n",
       "187244   selected             DFW  Senior Living   \n",
       "187245   selected             DFW  Senior Living   \n",
       "188097   selected  Northeast Ohio  Senior Living   \n",
       "186889   selected             DFW  Senior Living   \n",
       "\n",
       "                               facility_name  user_id  \n",
       "id                                                     \n",
       "190132                      Avenue at Medina    12134  \n",
       "191733           Avenue at Broadview Heights    17949  \n",
       "188967                             The Weils    18857  \n",
       "190536  Austin Retirement and Nursing Center    12807  \n",
       "190827                     Carriage Inn Katy    13273  \n",
       "...                                      ...      ...  \n",
       "191350             Brookdale Northwest Hills    11726  \n",
       "187244         The Hillcrest of North Dallas    12153  \n",
       "187245         The Hillcrest of North Dallas    12153  \n",
       "188097                  Ohio Living Rockynol     9113  \n",
       "186889         The Hillcrest of North Dallas    14645  \n",
       "\n",
       "[749 rows x 10 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only northeast ohio and stna, and make a pivot table\n",
    "# create a column called count\n",
    "pivot_table = validation[(validation['areaName'] == 'Northeast Ohio') & \n",
    "           (validation['type'] == 'STNA') & (validation['prob'] > 0.55)].groupby([\"Start_Time\",\n",
    "                                    \"Start_time_of_the_day\"]).size().reset_index(name='count').set_index(\"Start_Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the count is above limiter of 5\n",
    "# pivot_table['above_limiter'] = pivot_table.apply(lambda row: 2 if row['count'] >= 5 else 0, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_time_of_the_day</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>morning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>overnight</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>morning</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>overnight</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>morning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27</th>\n",
       "      <td>overnight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-28</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-28</th>\n",
       "      <td>morning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-29</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-29</th>\n",
       "      <td>overnight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-30</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-30</th>\n",
       "      <td>overnight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-06</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Start_time_of_the_day  count\n",
       "Start_Time                             \n",
       "2021-05-25             afternoon      1\n",
       "2021-05-25               morning      4\n",
       "2021-05-25             overnight      5\n",
       "2021-05-26             afternoon      2\n",
       "2021-05-26               morning      5\n",
       "2021-05-26             overnight      3\n",
       "2021-05-27             afternoon      2\n",
       "2021-05-27               morning      4\n",
       "2021-05-27             overnight      2\n",
       "2021-05-28             afternoon      1\n",
       "2021-05-28               morning      2\n",
       "2021-05-29               morning      1\n",
       "2021-05-29             overnight      1\n",
       "2021-05-30               morning      1\n",
       "2021-05-30             overnight      1\n",
       "2021-06-01               morning      1\n",
       "2021-06-03             afternoon      1\n",
       "2021-06-04             afternoon      1\n",
       "2021-06-06             afternoon      1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.to_excel(\"plan2_pred_{}.xlsx\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
