{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('model_data.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardlize, dont standardlize dummy! \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop(['id', 'user_id', 'shift_id', 'target', 'createdAt', 'start_time', 'type_RN', \n",
    "                    'type_LVN+LPN', 'segmentName_d', 'areaName_houston', 'areaName_no', 'areaName_dfw', \n",
    "                    'areaName_austin', 'areaName_san'], axis=1))\n",
    "scaled_features = scaler.transform(df.drop(['id', 'user_id', 'shift_id', 'target', 'createdAt',\n",
    "                                            'start_time', 'type_RN', 'type_LVN+LPN', 'segmentName_d', \n",
    "                                            'areaName_houston', 'areaName_no', 'areaName_dfw', \n",
    "                                            'areaName_austin', 'areaName_san'], axis=1))\n",
    "\n",
    "# scaled features\n",
    "X = pd.DataFrame(scaled_features, columns = ['prev_CW/SA_rate', 'prev_CW x SA_rate', 'S_create2SA_Create', \n",
    "                                             'S_Create2Start_Time', 'SA_Create2Start_Time', 'U_create2now', \n",
    "                                             'U_approve2now', 'net_pay'])\n",
    "# concat with dummy\n",
    "df = pd.concat([df[['id', 'user_id', 'shift_id', 'target', 'createdAt',\n",
    "                    'start_time', 'type_RN', 'type_LVN+LPN', 'segmentName_d', \n",
    "                    'areaName_houston', 'areaName_no', 'areaName_dfw', \n",
    "                    'areaName_austin', 'areaName_san']], X], axis = 1)\n",
    "\n",
    "# drop nas\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set future data point as realdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note !!!: real data might overlap with train test validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "realdata = df[df['start_time'].isin(pd.date_range('2021-3-22', '2021-3-29'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set: 1000 recently records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    984\n",
       "1     16\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice\n",
    "validation = df[-1000:]\n",
    "\n",
    "y_valid = validation['target']\n",
    "x_valid = validation.drop(['id','user_id', 'shift_id', 'createdAt', 'start_time', 'target'], axis = 1)\n",
    "\n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test: main dataset - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-1000] # slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset that num of tar = num of non tar, use it for train test\n",
    "import random\n",
    "df_tar = df[df['target']==1].reset_index(drop = True)\n",
    "df_nontar = df[df['target']==0].reset_index(drop = True)\n",
    "\n",
    "number_of_tar = df_tar.shape[0]\n",
    "random_indices = random.sample(range(len(df_nontar)), int(number_of_tar))\n",
    "df_nontar = df_nontar[df_nontar.index.isin(random_indices)]\n",
    "\n",
    "# concat\n",
    "df = pd.concat([df_tar, df_nontar]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id','user_id', 'shift_id', 'target', 'createdAt', 'start_time'], axis = 1)\n",
    "y = df['target']\n",
    "\n",
    "# set test, train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight={0: 1.0, 1: 2})"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "weights = {0:1.0, 1:2}\n",
    "dtree = DecisionTreeClassifier(class_weight = weights)\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[790 530]\n",
      " [570 724]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59      1320\n",
      "           1       0.58      0.56      0.57      1294\n",
      "\n",
      "    accuracy                           0.58      2614\n",
      "   macro avg       0.58      0.58      0.58      2614\n",
      "weighted avg       0.58      0.58      0.58      2614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# predict\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 365]\n",
      " [  4  12]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77       984\n",
      "           1       0.03      0.75      0.06        16\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.51      0.69      0.42      1000\n",
      "weighted avg       0.98      0.63      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = dtree.predict(x_valid)\n",
    "\n",
    "print(confusion_matrix(y_valid,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[880 440]\n",
      " [461 833]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1320\n",
      "           1       0.65      0.64      0.65      1294\n",
      "\n",
      "    accuracy                           0.66      2614\n",
      "   macro avg       0.66      0.66      0.66      2614\n",
      "weighted avg       0.66      0.66      0.66      2614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[600 384]\n",
      " [  3  13]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76       984\n",
      "           1       0.03      0.81      0.06        16\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.51      0.71      0.41      1000\n",
      "weighted avg       0.98      0.61      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(x_valid)\n",
    "\n",
    "print(confusion_matrix(y_valid, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests with significant var by LR\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_valid = validation['target']\n",
    "x_valid = validation[['prev_CW/SA_rate', 'net_pay', 'SA_Create2Start_Time', 'type_RN', \n",
    "                      'type_LVN+LPN', 'segmentName_d', 'areaName_houston', 'areaName_no',\n",
    "                      'areaName_dfw', 'areaName_austin', 'areaName_san']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['prev_CW/SA_rate', 'net_pay', 'SA_Create2Start_Time', 'type_RN', \n",
    "        'type_LVN+LPN', 'segmentName_d', 'areaName_houston', 'areaName_no',\n",
    "        'areaName_dfw', 'areaName_austin', 'areaName_san']]\n",
    "Y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[806 502]\n",
      " [506 800]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62      1308\n",
      "           1       0.61      0.61      0.61      1306\n",
      "\n",
      "    accuracy                           0.61      2614\n",
      "   macro avg       0.61      0.61      0.61      2614\n",
      "weighted avg       0.61      0.61      0.61      2614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[571 413]\n",
      " [  2  14]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73       984\n",
      "           1       0.03      0.88      0.06        16\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.51      0.73      0.40      1000\n",
      "weighted avg       0.98      0.58      0.72      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(x_valid)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_valid,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cf_matrix import make_confusion_matrix\n",
    "# labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "# categories = ['Zero', 'One']\n",
    "# make_confusion_matrix(confusion_matrix(y_valid,predictions), \n",
    "#                       group_names=labels,\n",
    "#                       categories=categories, \n",
    "#                       cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
