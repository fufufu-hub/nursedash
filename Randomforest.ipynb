{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('model_data.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardlize, dont standardlize dummy! \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop(['target', 'segmentName_d', 'type_d', 'createdAt', 'start_time'], axis=1))\n",
    "scaled_features = scaler.transform(df.drop(['target', 'segmentName_d', 'type_d', 'createdAt', 'start_time'], axis=1))\n",
    "\n",
    "# scaled features\n",
    "X = pd.DataFrame(scaled_features, columns = ['prev_CW/SA_rate', 'S_create2SA_Create', 'S_Create2Start_Time', \n",
    "                                             'SA_Create2Start_Time', 'U_create2now', 'U_approve2now', 'net_pay'])\n",
    "# concat with dummy\n",
    "df = pd.concat([X, df[['segmentName_d', 'type_d', 'target', 'createdAt', 'start_time']]], axis = 1)\n",
    "\n",
    "# drop nas\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set: 1000 recently records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    969\n",
       "1     31\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice\n",
    "validation = df[-1000:]\n",
    "\n",
    "y_valid = validation['target']\n",
    "x_valid = validation.drop(['createdAt', 'start_time', 'target'], axis = 1)\n",
    "\n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test: main dataset - validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-1000] # slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset that num of tar = num of non tar, use it for train test\n",
    "import random\n",
    "df_tar = df[df['target']==1].reset_index(drop = True)\n",
    "df_nontar = df[df['target']==0].reset_index(drop = True)\n",
    "\n",
    "number_of_tar = df_tar.shape[0]\n",
    "random_indices = random.sample(range(len(df_nontar)), int(number_of_tar))\n",
    "df_nontar = df_nontar[df_nontar.index.isin(random_indices)]\n",
    "\n",
    "# concat\n",
    "df = pd.concat([df_tar, df_nontar]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target', 'createdAt', 'start_time'], axis = 1)\n",
    "y = df['target']\n",
    "\n",
    "# set test, train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[760 538]\n",
      " [559 747]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.59      0.58      1298\n",
      "           1       0.58      0.57      0.58      1306\n",
      "\n",
      "    accuracy                           0.58      2604\n",
      "   macro avg       0.58      0.58      0.58      2604\n",
      "weighted avg       0.58      0.58      0.58      2604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# predict\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[558 411]\n",
      " [ 10  21]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.58      0.73       969\n",
      "           1       0.05      0.68      0.09        31\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.52      0.63      0.41      1000\n",
      "weighted avg       0.95      0.58      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = dtree.predict(x_valid)\n",
    "\n",
    "print(confusion_matrix(y_valid,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[844 454]\n",
      " [478 828]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64      1298\n",
      "           1       0.65      0.63      0.64      1306\n",
      "\n",
      "    accuracy                           0.64      2604\n",
      "   macro avg       0.64      0.64      0.64      2604\n",
      "weighted avg       0.64      0.64      0.64      2604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[611 358]\n",
      " [  8  23]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.63      0.77       969\n",
      "           1       0.06      0.74      0.11        31\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.52      0.69      0.44      1000\n",
      "weighted avg       0.96      0.63      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(x_valid)\n",
    "\n",
    "print(confusion_matrix(y_valid, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests with significant var by LR\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color = green> Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    969\n",
       "1     31\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid = validation['target']\n",
    "x_valid = validation[['prev_CW/SA_rate', 'type_d', 'segmentName_d', 'net_pay']]\n",
    "\n",
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['prev_CW/SA_rate', 'type_d', 'segmentName_d', 'net_pay']]\n",
    "Y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[843 500]\n",
      " [500 761]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1343\n",
      "           1       0.60      0.60      0.60      1261\n",
      "\n",
      "    accuracy                           0.62      2604\n",
      "   macro avg       0.62      0.62      0.62      2604\n",
      "weighted avg       0.62      0.62      0.62      2604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = green> Validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[595 374]\n",
      " [  8  23]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.61      0.76       969\n",
      "           1       0.06      0.74      0.11        31\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.52      0.68      0.43      1000\n",
      "weighted avg       0.96      0.62      0.74      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(x_valid)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_valid,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_valid,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cf_matrix import make_confusion_matrix\n",
    "# labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "# categories = ['Zero', 'One']\n",
    "# make_confusion_matrix(confusion_matrix(y_valid,predictions), \n",
    "#                       group_names=labels,\n",
    "#                       categories=categories, \n",
    "#                       cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
